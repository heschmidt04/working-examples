{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3: Text Generator\n",
        "\n",
        "⚠️   **Duplicate this project before you start working on it, using `File > Save a copy in drive`.**\n",
        "\n",
        "The goal of this project is to build a procedural text generator: a program that can generate random text that might actually make sense, based on some original real text. It might generate jokes, wise sayings, movie trailers, restaurant reviews, research papers - that part will be up to you!"
      ],
      "metadata": {
        "id": "9K8ZCt2F9hmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Markov chain\n",
        "\n",
        "A common approach for text generation these days might be a neural network trained on huge amounts of data, but we'll be using an older technique that requires very little data, and can be programmed entirely from scratch with what you know now in Python. Woo!\n",
        "\n",
        "The technique is called a **Markov chain** and is used in many industries to model sequences of events based on probabilities. Here, the sequence of events is the sequence of words in an English sentence, and the probabilities are the likelihood that one word is followed by another word.\n",
        "\n",
        "For example, we could create a model based solely on these sentences:\n",
        "\n",
        "* I am mad.\n",
        "* I am happy.\n",
        "* I love you.\n",
        "* I want cookies.\n",
        "* I love cookies.\n",
        "\n",
        "In this limited language (perhaps spoken by a toddler), the start word of every sentence is always \"I\". The next word has a 40% probability of being \"am\", a 40% probability of being \"love\", and a 20% probability of being \"want\". \n",
        "\n",
        "![Markov chain for I probabilities](https://corise.com/static/course/introduction-to-python/assets/cky534a6f00l01ga176er12br/markov_i.png)\n",
        "\n",
        "\n",
        "We can also compute the probabilities for the other words in the language. The word \"am\" has a 50% probability of being followed by \"mad\" and 50% probability of being followed by \"happy\". The word \"love\" has the same probabilities for \"you\" and \"cookies\". \n",
        "\n",
        "![Markov chain for am and love probabilities](https://corise.com/static/course/introduction-to-python/assets/cky537lac00l61ga18if91w9c/markov_amlove.png)\n",
        "\n",
        "The word \"want\" is only ever followed by \"cookies\" (toddlers know where it's at).\n",
        "\n",
        "![Markov chain for want probability](https://corise.com/static/course/introduction-to-python/assets/cky53j7wf00lb1ga15xpl85c9/markov_want.png)\n",
        "\n",
        "\n",
        "The remaining words all have a 100% probability of being followed by a period, meaning that they're always the last word in a sentence.\n",
        "\n",
        "![Markov chain for probabilities of you, cookies, mad, happy](https://corise.com/static/course/introduction-to-python/assets/cky532fpk00kr1ga16t6s9yjx/markov_madhappycookiesyou.png)\n",
        "\n",
        "\n",
        "We've now modeled this tiny language according to the probabilities of one word following another word, and we can use this model to generate sentences. We just start from a start word, which is always \"I\" in this language, and then pick the next word based on the probabilities and random dice rolls. Eventually, we'd generate all the original sentences in the language.\n",
        "\n",
        "But that's not very exciting, we want to generate new sentences! Well, if we added more and longer sentences to the input data, we'd likely eventually end up generating never-before-seen sentences. For example, if \"you want cookies\" was an input sentence, then the chain could generate \"I love you want cookies\", because it would observe that \"you\" could be followed by either a period or \"want\". \n",
        "\n",
        "![New sentence generated by chain](https://corise.com/static/course/introduction-to-python/assets/cky53rh0n00li1ga1crhkcsii/markov_newsentence.png)\n",
        "\n",
        "That particular sentence doesn't make grammatical sense, and many of the generated sentences won't, but trust me, some of the outputs will astound and amaze you.\n",
        "\n",
        "Now, it's time for you to actually build a Markov chain yourself. Ba-bum-bum!"
      ],
      "metadata": {
        "id": "uggt9jVm-J1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read input data\n",
        "\n",
        "What input data do you want to use for your Markov chain? It's up to you! Here are a few options:\n",
        "\n",
        "* [sayings.txt](https://gist.githubusercontent.com/pamelafox/ef698fe3a1a6950949e3987fe1303c07/raw/672570d0e002524f53c2f3b32dc0f70d905f5d1f/sayings.txt): ~2400 wise (or not so wise) sayings.\n",
        "* [titles.txt](https://gist.githubusercontent.com/pamelafox/cf569b133d717ab02c6635926ffc960a/raw/2c4913d8dd86a97ab602d48394638b24228e5ba2/movie_titles.txt): 6800 movie titles (which are on the shorter side, so your generated \"sentences\" will be quite short)\n",
        "* [composingprograms.txt](https://corise.com/static/course/introduction-to-python/assets/cky8zb2g800et1g4igmx1bjbz/python_textbook.txt): 3800 sentences from composingprograms.com, a textbook about Python, Scheme, and SQL.\n",
        "\n",
        "You're also welcome to use another data source, such as exporting your own social media posts or downloading a whole book from [Project Gutenberg](https://www.gutenberg.org/). Just be prepared to do a little more work cleaning the data into sentences.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "The code below already opens a URL and stores its lines in a variable.\n",
        "\n",
        "* Change the URL to your preferred data source. \n",
        "* If using the data sources above, right click and copy the link to get the full URL starting with `http`. \n",
        "* If you've uploaded a new data source as a file to CoLab, change the code to instead use the `open()` function with the filename.\n",
        "* Check that `sentences[0]` and `len(sentences)` are what you expected them to be."
      ],
      "metadata": {
        "id": "sb5RIVMeBYT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking at the Book Data (sentences) \n",
        "* Split the data on carriage return line feed \\r\\n\\r for ~2k of lines \n",
        "* Using a period loses the context of the sentences for ~4.6l of lines \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kHoIAezNbUs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# Open the file\n",
        "text_file = urllib.request.urlopen('https://www.gutenberg.org/files/61262/61262-0.txt')\n",
        "\n",
        "# Read the file into a string according to UTF-8 encoding\n",
        "text_contents = text_file.read().decode('utf-8')\n",
        "\n",
        "# Split the string into sentences (using newline as delimiter)\n",
        "sentences = text_contents.split('\\r\\n\\r')\n",
        "# sentences = text_contents.split('.')\n",
        "\n",
        "# Check a few sentences\n",
        "print(sentences[0])\n",
        "print(len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di5g9rekTAfS",
        "outputId": "b097395f-7b48-4e54-a04c-c49af037603c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg EBook of Poirot Investigates, by Agatha Christie\n",
            "2108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at data\n",
        "# Reviewed the 4.6 K of lines - narrowed down to 2k of lines and punctuation with 1st split\n",
        "sentences[0:12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-CFaCAYU5yj",
        "outputId": "fffdc8f9-df40-4010-e822-5ab39724fb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffThe Project Gutenberg EBook of Poirot Investigates, by Agatha Christie',\n",
              " \"\\nThis eBook is for the use of anyone anywhere in the United States and most\\r\\nother parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever.  You may copy it, give it away or re-use it under the terms of\\r\\nthe Project Gutenberg License included with this eBook or online at\\r\\nwww.gutenberg.org.  If you are not located in the United States, you'll have\\r\\nto check the laws of the country where you are located before using this ebook.\",\n",
              " '\\nTitle: Poirot Investigates',\n",
              " '\\nAuthor: Agatha Christie',\n",
              " '\\nRelease Date: January 28, 2020 [EBook #61262]',\n",
              " '\\nLanguage: English',\n",
              " '\\nCharacter set encoding: UTF-8',\n",
              " '\\n*** START OF THIS PROJECT GUTENBERG EBOOK POIROT INVESTIGATES ***',\n",
              " '\\n',\n",
              " '\\n\\r\\nProduced by an anonymous Project Gutenberg volunteer.',\n",
              " '\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "\n",
        "# This creates a dictionary that I can update with a number to see how many times the punctuation shows up. \n",
        "# It's here as a future stretch goal to pass to the function for punctuation and then use it for random generation \n",
        "punct_dict = dict.fromkeys(string.punctuation, [\"PUNCTUATION\"])\n",
        "punct_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbmavAp6_f4s",
        "outputId": "2f2e295e-8dc8-42d1-e137-2fe1d1b476ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': ['PUNCTUATION'],\n",
              " '\"': ['PUNCTUATION'],\n",
              " '#': ['PUNCTUATION'],\n",
              " '$': ['PUNCTUATION'],\n",
              " '%': ['PUNCTUATION'],\n",
              " '&': ['PUNCTUATION'],\n",
              " \"'\": ['PUNCTUATION'],\n",
              " '(': ['PUNCTUATION'],\n",
              " ')': ['PUNCTUATION'],\n",
              " '*': ['PUNCTUATION'],\n",
              " '+': ['PUNCTUATION'],\n",
              " ',': ['PUNCTUATION'],\n",
              " '-': ['PUNCTUATION'],\n",
              " '.': ['PUNCTUATION'],\n",
              " '/': ['PUNCTUATION'],\n",
              " ':': ['PUNCTUATION'],\n",
              " ';': ['PUNCTUATION'],\n",
              " '<': ['PUNCTUATION'],\n",
              " '=': ['PUNCTUATION'],\n",
              " '>': ['PUNCTUATION'],\n",
              " '?': ['PUNCTUATION'],\n",
              " '@': ['PUNCTUATION'],\n",
              " '[': ['PUNCTUATION'],\n",
              " '\\\\': ['PUNCTUATION'],\n",
              " ']': ['PUNCTUATION'],\n",
              " '^': ['PUNCTUATION'],\n",
              " '_': ['PUNCTUATION'],\n",
              " '`': ['PUNCTUATION'],\n",
              " '{': ['PUNCTUATION'],\n",
              " '|': ['PUNCTUATION'],\n",
              " '}': ['PUNCTUATION'],\n",
              " '~': ['PUNCTUATION']}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Translation (i.e. replacement or stripping of the character with no space) \n",
        "#     will be used by \n",
        "#     https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans\n",
        "# Examples here at: \n",
        "#     https://www.tutorialsteacher.com/python/string-maketrans\n",
        "\n",
        "strip_punct_dict ={ \n",
        "\t'/': '',\n",
        "\t'\\\\': '',\n",
        "\t'_': '',\n",
        "\t'\"': '',\n",
        "\t'“': '',\n",
        "\t'”': '',\n",
        "\t'-': '',\n",
        "\t':': '',\n",
        "\t';': '', \n",
        "\t'•': '',\n",
        "\t'‘': '',\n",
        "\t'\\n': ' ',\n",
        "\t'\\r': '',\n",
        "\t'—': ' ',\n",
        "}"
      ],
      "metadata": {
        "id": "OBxvaMlqADyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.python.org/2/library/string.html\n",
        "# string.maketrans(from, to)\n",
        "# Return a translation table suitable for passing to translate() if needed. \n",
        "# that will map each character in from into the character at the same \n",
        "# position in to; from and to must have the same length.\n",
        "\n",
        "# The strip_punct_dict was created by hand after review of the data\n",
        "# It could be generated dynamically. Left it out of scope for now to work on code mechanics \n",
        "remove_punct = str.maketrans(strip_punct_dict)\n",
        "remove_punct # returns the unicode value in decimal for the original character\n",
        "\n",
        "# Note: I could have removed more, yet I didn't want to do that on first go \n",
        "#       I wanted to see what fun the word with the punctuation would do for the random generated sentence \n",
        "#       I now know I'd like to leave the punctuation in and add variety at the end so it's not just a period "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkXoMGlkEPpI",
        "outputId": "a9b69929-327a-477b-c6e5-99d626a76836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: ' ',\n",
              " 13: '',\n",
              " 34: '',\n",
              " 45: '',\n",
              " 47: '',\n",
              " 58: '',\n",
              " 59: '',\n",
              " 92: '',\n",
              " 95: '',\n",
              " 8212: ' ',\n",
              " 8216: '',\n",
              " 8220: '',\n",
              " 8221: '',\n",
              " 8226: ''}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to reduce excess characters & lines after the translation \n",
        "\n",
        "cleaned_sentences = []\n",
        "\n",
        "for sentence in sentences:\n",
        "  sentence = sentence.lower()\n",
        "  sentence = sentence.strip('”')\n",
        "  sentence = sentence.lstrip()\n",
        "  sentence = sentence.rstrip()\n",
        "  sentence = sentence.translate(remove_punct)\n",
        "  if sentence.strip() != '': # throws away empty lines \n",
        "    cleaned_sentences.append(sentence) # appends only lines with data \n"
      ],
      "metadata": {
        "id": "I5YfYV3ZEDcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still a list of strings \n",
        "print(type(cleaned_sentences))\n",
        "# Slicing to see how it has evolved in iterations \n",
        "cleaned_sentences[2:10]  # I think it's going to be funny with a *** word :D "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUJRvB5IbZw",
        "outputId": "b3b768de-2e69-43c1-b9c2-0aac072fdc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['title poirot investigates',\n",
              " 'author agatha christie',\n",
              " 'release date january 28, 2020 [ebook #61262]',\n",
              " 'language english',\n",
              " 'character set encoding utf8',\n",
              " '*** start of this project gutenberg ebook poirot investigates ***',\n",
              " 'produced by an anonymous project gutenberg volunteer.',\n",
              " 'poirot investigates']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obsolete now -- left in to show how I built it in iterations \n",
        "# \n",
        "# Cleaned Sentences is the base for the other functions to use \n",
        "## cleaned_sentences = []\n",
        "## for line in in_text_after_translate[:]:\n",
        "##    line = line.lstrip()\n",
        "##    line = line.rstrip()\n",
        "##    if line.strip() != '': # throws away empty lines \n",
        "##        cleaned_sentences.append(line) # appends only lines with data \n"
      ],
      "metadata": {
        "id": "k9ELaV_2Lprr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing out the spilt of sentences and making all the text lower case \n",
        "\n",
        "#split_sentence = []\n",
        "#for sentence in cleaned_sentences[2:10]:\n",
        "#  sentence = sentence.lower()\n",
        "#  split_sentence.append(sentence.split())\n",
        "#\n",
        "# print(split_sentence)#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A1Jylln-uc_",
        "outputId": "afab8cc2-a411-47ff-8757-6ff290f46968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['title', 'poirot', 'investigates'], ['author', 'agatha', 'christie'], ['release', 'date', 'january', '28,', '2020', '[ebook', '#61262]'], ['language', 'english'], ['character', 'set', 'encoding', 'utf8'], ['***', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'poirot', 'investigates', '***'], ['produced', 'by', 'an', 'anonymous', 'project', 'gutenberg', 'volunteer.'], ['poirot', 'investigates']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_sentences)\n",
        "cleaned_sentences[200:220]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvmECl5H9_j9",
        "outputId": "b607fbae-18be-4fcf-d35c-ce95e2e51d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh, milord, i fear to incommode you. we have left our bags at the inn.',\n",
              " 'that’s all right. lord yardly had his cue. we’ll send down for them. no, no no trouble, i assure you.',\n",
              " 'poirot permitted himself to be persuaded, and sitting down by lady yardly, began to make friends with the children. in a short time they were all romping together, and had dragged me into the game.',\n",
              " 'vous êtes bonne mère, said poirot, with a gallant little bow, as the children were removed reluctantly by a stern nurse.',\n",
              " 'lady yardly smoothed her ruffled hair.',\n",
              " 'i adore them, she said with a little catch in her voice.',\n",
              " 'and they you with reason! poirot bowed again.',\n",
              " 'a dressinggong sounded, and we rose to go up to our rooms. at that moment the butler entered with a telegram on a salver which he handed to lord yardly. the latter tore it open with a brief word of apology. as he read it he stiffened visibly.',\n",
              " 'with an ejaculation, he handed it to his wife. then he glanced at my friend.',\n",
              " 'just a minute, monsieur poirot. i feel you ought to know about this. it’s from hoffberg. he thinks he’s found a customer for the diamond an american, sailing for the states tomorrow. they’re sending down a chap tonight to vet the stone. by jove, though, if this goes through   words failed him.',\n",
              " 'lady yardly had turned away. she still held the telegram in her hand.',\n",
              " 'i wish you wouldn’t sell it, george, she said, in a low voice. it’s been in the family so long. she waited, as though for a reply, but when none came her face hardened. she shrugged her shoulders. i must go and dress. i suppose i had better display the goods.’ she turned to poirot with a slight grimace. it’s one of the most hideous necklaces that was ever designed! george has always promised to have the stones reset for me, but it’s never been done. she left the room.',\n",
              " 'half an hour later, we three were assembled in the great drawingroom awaiting the lady. it was already a few minutes past the dinner hour.',\n",
              " 'suddenly there was a low rustle, and lady yardly appeared framed in the doorway, a radiant figure in a long white shimmering dress. round the column of her neck was a rivulet of fire. she stood there with one hand just touching the necklace.',\n",
              " 'behold the sacrifice, she said gaily. her illhumour seemed to have vanished. wait while i turn the big light on and you shall feast your eyes on the ugliest necklace in england.',\n",
              " 'the switches were just outside the door. as she stretched out her hand to them, the incredible thing happened. suddenly without any warning, every light was extinguished, the door banged, and from the other side of it came a longdrawn piercing woman’s scream.',\n",
              " 'my god! cried lord yardly. that was maude’s voice! what has happened?',\n",
              " 'we rushed blindly for the door, cannoning into each other in the darkness. it was some minutes before we could find it. what a sight met our eyes! lady yardly lay senseless on the marble floor, a crimson mark on her white throat where the necklace had been wrenched from her neck.',\n",
              " 'as we bent over her, uncertain for the moment whether she were dead or alive, her eyelids opened.',\n",
              " 'the chinaman, she whispered painfully. the chinaman the side door.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Markov chain\n",
        "\n",
        "For this project, you'll be storing the chain using a dictionary, with each key as a word, and each value as a list of words that come after that word. It's a great data structure for Markov chains since we can very quicky look up values by word.\n",
        "\n",
        "For example, the final chain for the simple toddler language would look like:\n",
        "\n",
        "```\n",
        "chain = {\n",
        "  \"START_OF_SENTENCE\": [\"I\"],\n",
        "  \"I\": [\"am\", \"am\", \"love\", \"want\", \"love\"],\n",
        "  \"am\": [\"mad\", \"happy\"],\n",
        "  \"love\": [\"you\", \"cookies\"],\n",
        "  \"want\": [\"cookies\"],\n",
        "  \"mad\": [\"END_OF_SENTENCE\"],\n",
        "  \"happy: [\"END_OF_SENTENCE\"],\n",
        "  \"you\": [\"END_OF_SENTENCE\"],\n",
        "  \"cookies\": [\"END_OF_SENTENCE\"]\n",
        "}\n",
        "```\n",
        "\n",
        "Every chain starts off with a word that isn't really a word - `START_OF_SENTENCE`. \n",
        "That key stores all the possible words that can start a sentence.\n",
        "\n",
        "As you can see, there's also a special not-word `END_OF_SENTENCE` indicating the end of the sentence, so that we know how often a word is followed by a period or new line.\n",
        "\n",
        "The values contain an entry for every time a word shows up after the key word, instead of storing the probability, simply because it's easier to code up that way. It'd also be possible to store the probabilities instead, if you wanted.\n",
        "\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Run the code below to initialize the chain with the single starting key:"
      ],
      "metadata": {
        "id": "XYUPvcMgLPsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = {\"START_OF_SENTENCE\": []}"
      ],
      "metadata": {
        "id": "Ebed06DQSFC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huE4OzjE-6xy",
        "outputId": "30793745-f201-4a57-948e-d1dc71a6414f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'START_OF_SENTENCE': []}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordify each sentence\n",
        "\n",
        "The `sentences` array right now contains strings that are entire sentences, but the chain dictionary needs keys and values that are words.\n",
        "\n",
        "In this step, you'll write a short function that can turn a sentence into a list of words. Use the string methods that we learned earlier in the week.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Implement `wordify_sentence` and run the doctests to make sure it works as expected.\n",
        "\n"
      ],
      "metadata": {
        "id": "bBi_jqrbait4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordify_sentence(clean_sentence):\n",
        "  \"\"\" \n",
        "  Splits a sentence into words (space-separated),\n",
        "  stripping off any periods at the end \n",
        "  and lowercasing all the words.\n",
        "  Leading and trailing whitespace should also be stripped.\n",
        "\n",
        "  >>> wordify_sentence('Money burns a hole in your pocket.')\n",
        "  ['money', 'burns', 'a', 'hole', 'in', 'your', 'pocket']\n",
        "  >>> wordify_sentence(' Miss Jerry\\\\n ')\n",
        "  ['miss', 'jerry']\n",
        "  \"\"\"\n",
        "  split_sentence = []\n",
        "  \n",
        "  words = clean_sentence.split()\n",
        "  for word in words:\n",
        "    split_sentence.append(word.lower().strip(\".\"))\n",
        "\n",
        "  return split_sentence \n",
        "\n",
        "wordify_sentence('a dressinggong sounded, and we rose to go up to our rooms. at that moment the butler entered with a telegram on a salver which he handed to lord yardly. the latter tore it open with a brief word of apology. as he read it he stiffened visibly.')\n"
      ],
      "metadata": {
        "id": "WKEYYWsEa-8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce3a9a3-e4bf-4195-e945-90a5e9e1f3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'dressinggong',\n",
              " 'sounded,',\n",
              " 'and',\n",
              " 'we',\n",
              " 'rose',\n",
              " 'to',\n",
              " 'go',\n",
              " 'up',\n",
              " 'to',\n",
              " 'our',\n",
              " 'rooms',\n",
              " 'at',\n",
              " 'that',\n",
              " 'moment',\n",
              " 'the',\n",
              " 'butler',\n",
              " 'entered',\n",
              " 'with',\n",
              " 'a',\n",
              " 'telegram',\n",
              " 'on',\n",
              " 'a',\n",
              " 'salver',\n",
              " 'which',\n",
              " 'he',\n",
              " 'handed',\n",
              " 'to',\n",
              " 'lord',\n",
              " 'yardly',\n",
              " 'the',\n",
              " 'latter',\n",
              " 'tore',\n",
              " 'it',\n",
              " 'open',\n",
              " 'with',\n",
              " 'a',\n",
              " 'brief',\n",
              " 'word',\n",
              " 'of',\n",
              " 'apology',\n",
              " 'as',\n",
              " 'he',\n",
              " 'read',\n",
              " 'it',\n",
              " 'he',\n",
              " 'stiffened',\n",
              " 'visibly']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests when you're ready\n",
        "import doctest\n",
        "doctest.run_docstring_examples(wordify_sentence, globals(), verbose=True, name=\"wordify_sentence\")"
      ],
      "metadata": {
        "id": "cyYEvLL4i_Si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ebdbfb-1aa2-4288-ae4b-3785434114a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding tests in wordify_sentence\n",
            "Trying:\n",
            "    wordify_sentence('Money burns a hole in your pocket.')\n",
            "Expecting:\n",
            "    ['money', 'burns', 'a', 'hole', 'in', 'your', 'pocket']\n",
            "ok\n",
            "Trying:\n",
            "    wordify_sentence(' Miss Jerry\\n ')\n",
            "Expecting:\n",
            "    ['miss', 'jerry']\n",
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Markov chain (Part 1)\n",
        "\n",
        "In this step, you'll make a function that can take a single sentence and update the chain based on each word in the sentence. If the word is the first word in the sentence, then it belongs in the value of the \"START_OF_SENTENCE\" key. If the word is followed by another word, then that subsequent word needs to be added to its value. Otherwise, if it's the last word in the sentence, then \"END_OF_SENTENCE\" needs to be added to its value.\n",
        "\n",
        "One tricky thing to look out for: the chain only starts off with a single key, \"START_SENTENCE\", so none of the other words in the sentences will exist as keys in the dictionary yet. Before you can update the values for those other words, you'll need to add a key in the dictionary for them and initialize it with an empty list - but only if it didn't exist yet!\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Implement the `add_sentence` function below, following the guidance in the comments. Run the doctests to see if it works as expected."
      ],
      "metadata": {
        "id": "_tPI8ajcXhBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sentence(chain, sentence):\n",
        "  \"\"\"\n",
        "  >>> test_chain = {'START_OF_SENTENCE': []}\n",
        "  >>> add_sentence(test_chain, 'I am happy')\n",
        "  >>> test_chain\n",
        "  {'START_OF_SENTENCE': ['i'], 'i': ['am'], 'am': ['happy'], 'happy': ['END_OF_SENTENCE']}\n",
        "  >>> add_sentence(test_chain, 'I am')\n",
        "  >>> test_chain\n",
        "  {'START_OF_SENTENCE': ['i', 'i'], 'i': ['am', 'am'], 'am': ['happy', 'END_OF_SENTENCE'], 'happy': ['END_OF_SENTENCE']}\n",
        "  \"\"\"\n",
        "  # Note the pattern is different for start and end of sentence. \n",
        "  # How you append below is going to be 3 different use cases to solve. \n",
        "\n",
        "  # Split the sentence into a list of words\n",
        "  words = wordify_sentence(sentence)\n",
        "\n",
        "  # Loop through each word in the list\n",
        "  # (Using a while loop gives you a way to know\n",
        "  # if the word is the first or the last)\n",
        "  i = 0\n",
        "  while i < len(words):\n",
        "    word = words[i]\n",
        "\n",
        "    # Handle case of first word in sentence\n",
        "    if i == 0:\n",
        "      chain[\"START_OF_SENTENCE\"].append(word)\n",
        "\n",
        "    # If word isn't in chain yet, add it as a key\n",
        "    if word not in chain:\n",
        "      chain[word] = []\n",
        "\n",
        "    # Now figure out what word to add to\n",
        "    # the list of values for this word\n",
        "  \n",
        "    # First, handle case of last word in sentence\n",
        "    if i == len(words) - 1:\n",
        "      chain[word].append(\"END_OF_SENTENCE\")\n",
        "    # Otherwise, handle case of a word that has a word after\n",
        "    else:\n",
        "      chain[word].append(words[i + 1])\n",
        "\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "ihNP8dKcLPeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests when you think add_sentence is working\n",
        "import doctest\n",
        "doctest.run_docstring_examples(add_sentence, globals(), verbose=True, name=\"add_sentence\")"
      ],
      "metadata": {
        "id": "BUlVuNmLiOWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58cc8ec-a630-49a6-804e-40ab469af9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding tests in add_sentence\n",
            "Trying:\n",
            "    test_chain = {'START_OF_SENTENCE': []}\n",
            "Expecting nothing\n",
            "ok\n",
            "Trying:\n",
            "    add_sentence(test_chain, 'I am happy')\n",
            "Expecting nothing\n",
            "ok\n",
            "Trying:\n",
            "    test_chain\n",
            "Expecting:\n",
            "    {'START_OF_SENTENCE': ['i'], 'i': ['am'], 'am': ['happy'], 'happy': ['END_OF_SENTENCE']}\n",
            "ok\n",
            "Trying:\n",
            "    add_sentence(test_chain, 'I am')\n",
            "Expecting nothing\n",
            "ok\n",
            "Trying:\n",
            "    test_chain\n",
            "Expecting:\n",
            "    {'START_OF_SENTENCE': ['i', 'i'], 'i': ['am', 'am'], 'am': ['happy', 'END_OF_SENTENCE'], 'happy': ['END_OF_SENTENCE']}\n",
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Markov chain (Part 2)\n",
        "\n",
        "Now that you've got `add_sentence` working, it's time to call it on every sentence from your input data."
      ],
      "metadata": {
        "id": "EaM9i9rziyU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏︎ For you to do\n",
        "\n",
        "Use a loop to go through each sentence in `sentences` (the list of sentences stored above) and call `add_sentence` on each of them. Once you've done that, you can log out the entire `chain` dictionary to see what it looks like, or just a single key, like `chain[\"the\"]`."
      ],
      "metadata": {
        "id": "iGs1X8Wde4wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR LOOP HERE\n",
        "chain = {\"START_OF_SENTENCE\":[]}\n",
        "\n",
        "for sentence in cleaned_sentences[0:100]:\n",
        "  add_sentence(chain=chain, sentence=sentence)\n",
        "print(chain[\"the\"]) # This is only printing a subset. :D \n"
      ],
      "metadata": {
        "id": "NGzn4p3Fe1yV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3942ef-46bd-404e-fcb9-f75c1b779b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['use', 'united', 'world', 'terms', 'project', 'united', 'laws', 'country', 'same', 'mysterious', 'secret', 'murder', 'links', 'bodley', 'bodley', 'bodley', 'adventure', 'western', 'tragedy', 'adventure', 'cheap', 'mystery', 'million', 'adventure', 'egyptian', 'grand', 'kidnapped', 'disappearance', 'adventure', 'italian', 'case', 'missing', 'adventure', 'western', 'window', 'street', 'depths', 'following', 'houses', 'girl,', 'girl', 'shadowers', 'scoundrels,', 'great', 'great', 'simplest', 'window', 'film', 'fact!', 'screen,', 'streets', 'nonessentials!', 'case', 'dancer,', 'best', 'mode,', 'dernier', 'little', 'most', 'american', 'most', 'screen', 'states', 'great', 'western', 'enormous', 'wide', 'mystery', 'dark', 'latter', 'name', 'inside', 'enclosure', 'writing', 'envelope', 'great', 'left', 'god', 'second', 'same', 'third', 'diamond', 'full', 'moon,', 'two', 'left', 'god', 'first', 'second,', 'third', 'matter', 'stone', 'diamond', 'western', 'time,', 'stone,', 'chink', 'thing', 'story', 'leaves', 'date', 'full', 'diamond', 'actress’s', 'girl', 'bosom', 'palm,', 'jewel', 'hotel', 'magnificent,', 'states,', 'pace', 'assistance', 'show']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_sentences[0:100] # notice that the one \\ufeff is the starting character which I left in. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVYoc-Tr5qDA",
        "outputId": "e0258f9d-77f9-4fde-dfee-89060a77980a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffthe project gutenberg ebook of poirot investigates, by agatha christie',\n",
              " \"this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org.  if you are not located in the united states, you'll have to check the laws of the country where you are located before using this ebook.\",\n",
              " 'title poirot investigates',\n",
              " 'author agatha christie',\n",
              " 'release date january 28, 2020 [ebook #61262]',\n",
              " 'language english',\n",
              " 'character set encoding utf8',\n",
              " '*** start of this project gutenberg ebook poirot investigates ***',\n",
              " 'produced by an anonymous project gutenberg volunteer.',\n",
              " 'poirot investigates',\n",
              " 'by the same author',\n",
              " 'the mysterious affair at styles',\n",
              " 'the secret adversary',\n",
              " 'the murder on the links',\n",
              " 'the bodley head',\n",
              " 'poirot investigates',\n",
              " 'by agatha christie',\n",
              " 'london',\n",
              " 'john lane the bodley head limited',\n",
              " 'first published in great britain by   john lane company, the bodley head limited, 1924',\n",
              " 'copyright © 1924 agatha christie limited',\n",
              " 'contents',\n",
              " 'i the adventure of the western star',\n",
              " 'ii the tragedy at marsdon manor',\n",
              " 'iii the adventure of the cheap flat',\n",
              " 'iv the mystery of hunter’s lodge',\n",
              " 'v the million dollar bond robbery',\n",
              " 'vi the adventure of the egyptian tomb',\n",
              " 'vii jewel robbery at the grand metropolitan',\n",
              " 'viii the kidnapped prime minister',\n",
              " 'ix the disappearance of mr. davenheim',\n",
              " 'x the adventure of the italian nobleman',\n",
              " 'xi the case of the missing will',\n",
              " 'poirot investigates',\n",
              " 'poirot investigates',\n",
              " 'i',\n",
              " 'the adventure of the western star',\n",
              " 'i was standing at the window of poirot’s rooms looking out idly on the street below.',\n",
              " 'that’s queer, i ejaculated suddenly beneath my breath.',\n",
              " 'what is, mon ami? asked poirot placidly, from the depths of his comfortable chair.',\n",
              " 'deduce, poirot, from the following facts! here is a young lady, richly dressed fashionable hat, magnificent furs. she is coming along slowly, looking up at the houses as she goes. unknown to her, she is being shadowed by three men and a middleaged woman. they have just been joined by an errand boy who points after the girl, gesticulating as he does so. what drama is this being played? is the girl a crook, and are the shadowers detectives preparing to arrest her? or are they the scoundrels, and are they plotting to attack an innocent victim? what does the great detective say?',\n",
              " 'the great detective, mon ami, chooses, as ever, the simplest course. he rises to see for himself. and my friend joined me at the window.',\n",
              " 'in a minute he gave vent to an amused chuckle.',\n",
              " 'as usual, your facts are tinged with your incurable romanticism. that is miss mary marvell, the film star. she is being followed by a bevy of admirers who have recognized her. and, en passant, my dear hastings, she is quite aware of the fact!',\n",
              " 'i laughed.',\n",
              " 'so all is explained! but you get no marks for that, poirot. it was a mere matter of recognition.',\n",
              " 'en vérité! and how many times have you seen mary marvell on the screen, mon cher?',\n",
              " 'i thought.',\n",
              " 'about a dozen times perhaps.',\n",
              " 'and i once! yet i recognize her, and you do not.',\n",
              " 'she looks so different, i replied rather feebly.',\n",
              " 'ah! sacré! cried poirot. is it that you expect her to promenade herself in the streets of london in a cowboy hat, or with bare feet, and a bunch of curls, as an irish colleen? always with you it is the nonessentials! remember the case of the dancer, valerie saintclair.',\n",
              " 'i shrugged my shoulders, slightly annoyed.',\n",
              " 'but console yourself, mon ami, said poirot, calming down. all cannot be as hercule poirot! i know it well.',\n",
              " 'you really have the best opinion of yourself of anyone i ever knew! i cried, divided between amusement and annoyance.',\n",
              " 'what will you? when one is unique, one knows it! and others share that opinion even, if i mistake not, miss mary marvell.',\n",
              " 'what?',\n",
              " 'without doubt. she is coming here.',\n",
              " 'how do you make that out?',\n",
              " 'very simply. this street, it is not aristocratic, mon ami! in it there is no fashionable doctor, no fashionable dentist still less is there a fashionable milliner! but there is a fashionable detective. oui, my friend, it is true i am become the mode, the dernier cri! one says to another comment? you have lost your gold pencilcase? you must go to the little belgian. he is too marvellous! every one goes! courez!’ and they arrive! in flocks, mon ami! with problems of the most foolish! a bell rang below. what did i tell you? that is miss marvell.',\n",
              " 'as usual, poirot was right. after a short interval, the american film star was ushered in, and we rose to our feet.',\n",
              " 'mary marvell was undoubtedly one of the most popular actresses on the screen. she had only lately arrived in england in company with her husband, gregory b. rolf, also a film actor. their marriage had taken place about a year ago in the states and this was their first visit to england. they had been given a great reception. every one was prepared to go mad over mary marvell, her wonderful clothes, her furs, her jewels, above all one jewel, the great diamond which had been nicknamed, to match its owner, the western star. much, true and untrue, had been written about this famous stone which was reported to be insured for the enormous sum of fifty thousand pounds.',\n",
              " 'all these details passed rapidly through my mind as i joined with poirot in greeting our fair client.',\n",
              " 'miss marvell was small and slender, very fair and girlishlooking, with the wide innocent blue eyes of a child.',\n",
              " 'poirot drew forward a chair for her, and she commenced talking at once.',\n",
              " 'you will probably think me very foolish, monsieur poirot, but lord cronshaw was telling me last night how wonderfully you cleared up the mystery of his nephew’s death, and i felt that i just must have your advice. i dare say it’s only a silly hoax gregory says so but it’s just worrying me to death.',\n",
              " 'she paused for breath. poirot beamed encouragement.',\n",
              " 'proceed, madame. you comprehend, i am still in the dark.',\n",
              " 'it’s these letters. miss marvell unclasped her handbag, and drew out three envelopes which she handed to poirot.',\n",
              " 'the latter scrutinized them closely.',\n",
              " 'cheap paper the name and address carefully printed. let us see the inside. he drew out the enclosure.',\n",
              " 'i had joined him, and was leaning over his shoulder. the writing consisted of a single sentence, carefully printed like the envelope. it ran as follows',\n",
              " 'the great diamond which is the left eye of the god must return whence it came.',\n",
              " 'the second letter was couched in precisely the same terms, but the third was more explicit',\n",
              " 'you have been warned. you have not obeyed. now the diamond will be taken from you. at the full of the moon, the two diamonds which are the left and right eye of the god shall return. so it is written.',\n",
              " 'the first letter i treated as a joke, explained miss marvell. when i got the second, i began to wonder. the third one came yesterday, and it seemed to me that, after all, the matter might be more serious than i had imagined.',\n",
              " 'i see they did not come by post, these letters.',\n",
              " 'no they were left by hand by a chinaman. that is what frightens me.',\n",
              " 'why?',\n",
              " 'because it was from a chink in san francisco that gregory bought the stone three years ago.',\n",
              " 'i see, madame, that you believe the diamond referred to to be  ',\n",
              " 'the western star,’ finished miss marvell. that’s so. at the time, gregory remembers that there was some story attached to the stone, but the chink wasn’t handing out any information. gregory says he seemed just scared to death, and in a mortal hurry to get rid of the thing. he only asked about a tenth of its value. it was greg’s wedding present to me.',\n",
              " 'poirot nodded thoughtfully.',\n",
              " 'the story seems of an almost unbelievable romanticism. and yet who knows? i pray of you, hastings, hand me my little almanac.',\n",
              " 'i complied.',\n",
              " 'voyons! said poirot, turning the leaves.',\n",
              " 'when is the date of the full moon? ah, friday next. that is in three days’ time. eh bien, madame, you seek my advice i give it to you. this belle histoire may be a hoax but it may not! therefore i counsel you to place the diamond in my keeping until after friday next. then we can take what steps we please.',\n",
              " 'a slight cloud passed over the actress’s face, and she replied constrainedly',\n",
              " 'i’m afraid that’s impossible.',\n",
              " 'you have it with you hein? poirot was watching her narrowly.',\n",
              " 'the girl hesitated a moment, then slipped her hand into the bosom of her gown, drawing out a long thin chain. she leaned forward, unclosing her hand. in the palm, a stone of white fire, exquisitely set in platinum, lay and winked at us solemnly.',\n",
              " 'poirot drew in his breath with a long hiss.',\n",
              " 'épatant! he murmured. you permit, madame? he took the jewel in his own hand and scrutinized it keenly, then restored it to her with a little bow. a magnificent stone without a flaw. ah, cent tonnerres! and you carry it about with you, comme ça!',\n",
              " 'no, no, i’m very careful really, monsieur poirot. as a rule it’s locked up in my jewelcase, and left in the hotel safe deposit. we’re staying at the magnificent, you know. i just brought it along today for you to see.',\n",
              " 'and you will leave it with me, n’estce pas? you will be advised by papa poirot?',\n",
              " 'well, you see, it’s this way, monsieur poirot. on friday we’re going down to yardly chase to spend a few days with lord and lady yardly.',\n",
              " 'her words awoke a vague echo of remembrance in my mind. some gossip what was it now? a few years ago lord and lady yardly had paid a visit to the states, rumour had it that his lordship had rather gone the pace out there with the assistance of some lady friends but surely there was something more, some gossip which coupled lady yardly’s name with that of a movie star in california why! it came to me in a flash of course it was none other than gregory b. rolf.',\n",
              " 'i’ll let you into a little secret, monsieur poirot, miss marvell was continuing. we’ve got a deal on with lord yardly. there’s some chance of our arranging to film a play down there in his ancestral pile.',\n",
              " 'at yardly chase? i cried, interested. why, it’s one of the show places of england.',\n",
              " 'miss marvell nodded.']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain # really cool to see the contents of the chain... this would make a cool heat map where the most frequent words are larger vs 1 offs smaller\n",
        "\n",
        "\"\"\"\n",
        "This was cool to see that end of sentence was repeated\n",
        "\n",
        "'christie': ['END_OF_SENTENCE',\n",
        "  'END_OF_SENTENCE',\n",
        "  'END_OF_SENTENCE',\n",
        "  'limited']\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egs3teZO5c7K",
        "outputId": "0633ae6c-dd0b-4c7d-df9d-145f4eac5830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#61262]': ['END_OF_SENTENCE'],\n",
              " '***': ['start', 'END_OF_SENTENCE'],\n",
              " '1924': ['END_OF_SENTENCE', 'agatha'],\n",
              " '2020': ['[ebook'],\n",
              " '28,': ['2020'],\n",
              " 'START_OF_SENTENCE': ['\\ufeffthe',\n",
              "  'this',\n",
              "  'title',\n",
              "  'author',\n",
              "  'release',\n",
              "  'language',\n",
              "  'character',\n",
              "  '***',\n",
              "  'produced',\n",
              "  'poirot',\n",
              "  'by',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'poirot',\n",
              "  'by',\n",
              "  'london',\n",
              "  'john',\n",
              "  'first',\n",
              "  'copyright',\n",
              "  'contents',\n",
              "  'i',\n",
              "  'ii',\n",
              "  'iii',\n",
              "  'iv',\n",
              "  'v',\n",
              "  'vi',\n",
              "  'vii',\n",
              "  'viii',\n",
              "  'ix',\n",
              "  'x',\n",
              "  'xi',\n",
              "  'poirot',\n",
              "  'poirot',\n",
              "  'i',\n",
              "  'the',\n",
              "  'i',\n",
              "  'that’s',\n",
              "  'what',\n",
              "  'deduce,',\n",
              "  'the',\n",
              "  'in',\n",
              "  'as',\n",
              "  'i',\n",
              "  'so',\n",
              "  'en',\n",
              "  'i',\n",
              "  'about',\n",
              "  'and',\n",
              "  'she',\n",
              "  'ah!',\n",
              "  'i',\n",
              "  'but',\n",
              "  'you',\n",
              "  'what',\n",
              "  'what?',\n",
              "  'without',\n",
              "  'how',\n",
              "  'very',\n",
              "  'as',\n",
              "  'mary',\n",
              "  'all',\n",
              "  'miss',\n",
              "  'poirot',\n",
              "  'you',\n",
              "  'she',\n",
              "  'proceed,',\n",
              "  'it’s',\n",
              "  'the',\n",
              "  'cheap',\n",
              "  'i',\n",
              "  'the',\n",
              "  'the',\n",
              "  'you',\n",
              "  'the',\n",
              "  'i',\n",
              "  'no',\n",
              "  'why?',\n",
              "  'because',\n",
              "  'i',\n",
              "  'the',\n",
              "  'poirot',\n",
              "  'the',\n",
              "  'i',\n",
              "  'voyons!',\n",
              "  'when',\n",
              "  'a',\n",
              "  'i’m',\n",
              "  'you',\n",
              "  'the',\n",
              "  'poirot',\n",
              "  'épatant!',\n",
              "  'no,',\n",
              "  'and',\n",
              "  'well,',\n",
              "  'her',\n",
              "  'i’ll',\n",
              "  'at',\n",
              "  'miss'],\n",
              " '[ebook': ['#61262]'],\n",
              " 'a': ['young',\n",
              "  'middleaged',\n",
              "  'crook,',\n",
              "  'minute',\n",
              "  'bevy',\n",
              "  'mere',\n",
              "  'dozen',\n",
              "  'cowboy',\n",
              "  'bunch',\n",
              "  'fashionable',\n",
              "  'fashionable',\n",
              "  'bell',\n",
              "  'short',\n",
              "  'film',\n",
              "  'year',\n",
              "  'great',\n",
              "  'child',\n",
              "  'chair',\n",
              "  'silly',\n",
              "  'single',\n",
              "  'joke,',\n",
              "  'chinaman',\n",
              "  'chink',\n",
              "  'mortal',\n",
              "  'tenth',\n",
              "  'hoax',\n",
              "  'slight',\n",
              "  'moment,',\n",
              "  'long',\n",
              "  'stone',\n",
              "  'long',\n",
              "  'little',\n",
              "  'magnificent',\n",
              "  'flaw',\n",
              "  'rule',\n",
              "  'few',\n",
              "  'vague',\n",
              "  'few',\n",
              "  'visit',\n",
              "  'movie',\n",
              "  'flash',\n",
              "  'little',\n",
              "  'deal',\n",
              "  'play'],\n",
              " 'about': ['a', 'a', 'this', 'a', 'with'],\n",
              " 'above': ['all'],\n",
              " 'actor': ['their'],\n",
              " 'actresses': ['on'],\n",
              " 'actress’s': ['face,'],\n",
              " 'address': ['carefully'],\n",
              " 'admirers': ['who'],\n",
              " 'adventure': ['of', 'of', 'of', 'of', 'of'],\n",
              " 'adversary': ['END_OF_SENTENCE'],\n",
              " 'advice': ['i', 'i'],\n",
              " 'advised': ['by'],\n",
              " 'affair': ['at'],\n",
              " 'afraid': ['that’s'],\n",
              " 'after': ['the', 'a', 'all,', 'friday'],\n",
              " 'agatha': ['christie', 'christie', 'christie', 'christie'],\n",
              " 'ago': ['in', 'END_OF_SENTENCE', 'lord'],\n",
              " 'ah!': ['sacré!'],\n",
              " 'ah,': ['friday', 'cent'],\n",
              " 'all': ['is', 'cannot', 'one', 'these'],\n",
              " 'all,': ['the'],\n",
              " 'almanac': ['END_OF_SENTENCE'],\n",
              " 'almost': ['no', 'unbelievable'],\n",
              " 'along': ['slowly,', 'today'],\n",
              " 'also': ['a'],\n",
              " 'always': ['with'],\n",
              " 'am': ['become', 'still'],\n",
              " 'american': ['film'],\n",
              " 'ami!': ['in', 'with'],\n",
              " 'ami,': ['chooses,', 'said'],\n",
              " 'ami?': ['asked'],\n",
              " 'amused': ['chuckle'],\n",
              " 'amusement': ['and'],\n",
              " 'an': ['anonymous', 'errand', 'innocent', 'amused', 'irish', 'almost'],\n",
              " 'ancestral': ['pile'],\n",
              " 'and': ['most',\n",
              "  'with',\n",
              "  'a',\n",
              "  'are',\n",
              "  'are',\n",
              "  'my',\n",
              "  'how',\n",
              "  'i',\n",
              "  'you',\n",
              "  'a',\n",
              "  'annoyance',\n",
              "  'others',\n",
              "  'they',\n",
              "  'we',\n",
              "  'this',\n",
              "  'untrue,',\n",
              "  'slender,',\n",
              "  'girlishlooking,',\n",
              "  'she',\n",
              "  'i',\n",
              "  'drew',\n",
              "  'address',\n",
              "  'was',\n",
              "  'right',\n",
              "  'it',\n",
              "  'in',\n",
              "  'yet',\n",
              "  'she',\n",
              "  'winked',\n",
              "  'scrutinized',\n",
              "  'you',\n",
              "  'left',\n",
              "  'you',\n",
              "  'lady',\n",
              "  'lady'],\n",
              " 'and,': ['en'],\n",
              " 'annoyance': ['END_OF_SENTENCE'],\n",
              " 'annoyed': ['END_OF_SENTENCE'],\n",
              " 'anonymous': ['project'],\n",
              " 'another': ['comment?'],\n",
              " 'any': ['information'],\n",
              " 'anyone': ['anywhere', 'i'],\n",
              " 'anywhere': ['in'],\n",
              " 'are': ['not', 'located', 'the', 'they', 'they', 'tinged', 'the'],\n",
              " 'aristocratic,': ['mon'],\n",
              " 'arranging': ['to'],\n",
              " 'arrest': ['her?'],\n",
              " 'arrive!': ['in'],\n",
              " 'arrived': ['in'],\n",
              " 'as': ['she',\n",
              "  'he',\n",
              "  'ever,',\n",
              "  'usual,',\n",
              "  'an',\n",
              "  'hercule',\n",
              "  'usual,',\n",
              "  'i',\n",
              "  'follows',\n",
              "  'a',\n",
              "  'a'],\n",
              " 'asked': ['poirot', 'about'],\n",
              " 'assistance': ['of'],\n",
              " 'at': ['no',\n",
              "  'www.gutenberg.org',\n",
              "  'styles',\n",
              "  'marsdon',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'once',\n",
              "  'the',\n",
              "  'the',\n",
              "  'us',\n",
              "  'the',\n",
              "  'yardly'],\n",
              " 'attached': ['to'],\n",
              " 'attack': ['an'],\n",
              " 'author': ['agatha', 'END_OF_SENTENCE'],\n",
              " 'aware': ['of'],\n",
              " 'away': ['or'],\n",
              " 'awoke': ['a'],\n",
              " 'b': ['rolf,', 'rolf'],\n",
              " 'bare': ['feet,'],\n",
              " 'be': ['as', 'insured', 'taken', 'more', 'END_OF_SENTENCE', 'a', 'advised'],\n",
              " 'beamed': ['encouragement'],\n",
              " 'because': ['it'],\n",
              " 'become': ['the'],\n",
              " 'been': ['joined', 'given', 'nicknamed,', 'written', 'warned'],\n",
              " 'before': ['using'],\n",
              " 'began': ['to'],\n",
              " 'being': ['shadowed', 'played?', 'followed'],\n",
              " 'belgian': ['he'],\n",
              " 'believe': ['the'],\n",
              " 'bell': ['rang'],\n",
              " 'belle': ['histoire'],\n",
              " 'below': ['END_OF_SENTENCE', 'what'],\n",
              " 'beneath': ['my'],\n",
              " 'best': ['opinion'],\n",
              " 'between': ['amusement'],\n",
              " 'bevy': ['of'],\n",
              " 'bien,': ['madame,'],\n",
              " 'blue': ['eyes'],\n",
              " 'bodley': ['head', 'head', 'head'],\n",
              " 'bond': ['robbery'],\n",
              " 'bosom': ['of'],\n",
              " 'bought': ['the'],\n",
              " 'bow': ['a'],\n",
              " 'boy': ['who'],\n",
              " 'breath': ['END_OF_SENTENCE', 'poirot', 'with'],\n",
              " 'britain': ['by'],\n",
              " 'brought': ['it'],\n",
              " 'bunch': ['of'],\n",
              " 'but': ['you',\n",
              "  'console',\n",
              "  'there',\n",
              "  'lord',\n",
              "  'it’s',\n",
              "  'the',\n",
              "  'the',\n",
              "  'it',\n",
              "  'surely'],\n",
              " 'by': ['agatha',\n",
              "  'an',\n",
              "  'the',\n",
              "  'agatha',\n",
              "  'john',\n",
              "  'three',\n",
              "  'an',\n",
              "  'a',\n",
              "  'post,',\n",
              "  'hand',\n",
              "  'a',\n",
              "  'papa'],\n",
              " 'california': ['why!'],\n",
              " 'calming': ['down'],\n",
              " 'came': ['END_OF_SENTENCE', 'yesterday,', 'to'],\n",
              " 'can': ['take'],\n",
              " 'cannot': ['be'],\n",
              " 'careful': ['really,'],\n",
              " 'carefully': ['printed', 'printed'],\n",
              " 'carry': ['it'],\n",
              " 'case': ['of', 'of'],\n",
              " 'cent': ['tonnerres!'],\n",
              " 'chain': ['she'],\n",
              " 'chair': ['END_OF_SENTENCE', 'for'],\n",
              " 'chance': ['of'],\n",
              " 'character': ['set'],\n",
              " 'chase': ['to'],\n",
              " 'chase?': ['i'],\n",
              " 'cheap': ['flat', 'paper'],\n",
              " 'check': ['the'],\n",
              " 'cher?': ['END_OF_SENTENCE'],\n",
              " 'child': ['END_OF_SENTENCE'],\n",
              " 'chinaman': ['that'],\n",
              " 'chink': ['in', 'wasn’t'],\n",
              " 'chooses,': ['as'],\n",
              " 'christie': ['END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'limited'],\n",
              " 'chuckle': ['END_OF_SENTENCE'],\n",
              " 'cleared': ['up'],\n",
              " 'client': ['END_OF_SENTENCE'],\n",
              " 'closely': ['END_OF_SENTENCE'],\n",
              " 'clothes,': ['her'],\n",
              " 'cloud': ['passed'],\n",
              " 'colleen?': ['always'],\n",
              " 'come': ['by'],\n",
              " 'comfortable': ['chair'],\n",
              " 'coming': ['along', 'here'],\n",
              " 'comme': ['ça!'],\n",
              " 'commenced': ['talking'],\n",
              " 'comment?': ['you'],\n",
              " 'company': ['with'],\n",
              " 'company,': ['the'],\n",
              " 'complied': ['END_OF_SENTENCE'],\n",
              " 'comprehend,': ['i'],\n",
              " 'consisted': ['of'],\n",
              " 'console': ['yourself,'],\n",
              " 'constrainedly': ['END_OF_SENTENCE'],\n",
              " 'contents': ['END_OF_SENTENCE'],\n",
              " 'continuing': ['we’ve'],\n",
              " 'copy': ['it,'],\n",
              " 'copyright': ['©'],\n",
              " 'cost': ['and'],\n",
              " 'couched': ['in'],\n",
              " 'counsel': ['you'],\n",
              " 'country': ['where'],\n",
              " 'coupled': ['lady'],\n",
              " 'courez!’': ['and'],\n",
              " 'course': ['he', 'it'],\n",
              " 'cowboy': ['hat,'],\n",
              " 'cri!': ['one'],\n",
              " 'cried': ['poirot'],\n",
              " 'cried,': ['divided', 'interested'],\n",
              " 'cronshaw': ['was'],\n",
              " 'crook,': ['and'],\n",
              " 'curls,': ['as'],\n",
              " 'dancer,': ['valerie'],\n",
              " 'dare': ['say'],\n",
              " 'dark': ['END_OF_SENTENCE'],\n",
              " 'date': ['january', 'of'],\n",
              " 'davenheim': ['END_OF_SENTENCE'],\n",
              " 'days': ['with'],\n",
              " 'days’': ['time'],\n",
              " 'deal': ['on'],\n",
              " 'dear': ['hastings,'],\n",
              " 'death': ['END_OF_SENTENCE'],\n",
              " 'death,': ['and', 'and'],\n",
              " 'deduce,': ['poirot,'],\n",
              " 'dentist': ['still'],\n",
              " 'deposit': ['we’re'],\n",
              " 'depths': ['of'],\n",
              " 'dernier': ['cri!'],\n",
              " 'details': ['passed'],\n",
              " 'detective': ['say?', 'oui,'],\n",
              " 'detective,': ['mon'],\n",
              " 'detectives': ['preparing'],\n",
              " 'diamond': ['which', 'which', 'will', 'referred', 'in'],\n",
              " 'diamonds': ['which'],\n",
              " 'did': ['i', 'not'],\n",
              " 'different,': ['i'],\n",
              " 'disappearance': ['of'],\n",
              " 'divided': ['between'],\n",
              " 'do': ['not', 'you'],\n",
              " 'doctor,': ['no'],\n",
              " 'does': ['so', 'the'],\n",
              " 'dollar': ['bond'],\n",
              " 'doubt': ['she'],\n",
              " 'down': ['all', 'to', 'there'],\n",
              " 'dozen': ['times'],\n",
              " 'drama': ['is'],\n",
              " 'drawing': ['out'],\n",
              " 'dressed': ['fashionable'],\n",
              " 'drew': ['forward', 'out', 'out', 'in'],\n",
              " 'ebook': ['of', 'is', 'or', 'END_OF_SENTENCE', 'poirot'],\n",
              " 'echo': ['of'],\n",
              " 'egyptian': ['tomb'],\n",
              " 'eh': ['bien,'],\n",
              " 'ejaculated': ['suddenly'],\n",
              " 'en': ['passant,', 'vérité!'],\n",
              " 'enclosure': ['END_OF_SENTENCE'],\n",
              " 'encoding': ['utf8'],\n",
              " 'encouragement': ['END_OF_SENTENCE'],\n",
              " 'england': ['in', 'they', 'END_OF_SENTENCE'],\n",
              " 'english': ['END_OF_SENTENCE'],\n",
              " 'enormous': ['sum'],\n",
              " 'envelope': ['it'],\n",
              " 'envelopes': ['which'],\n",
              " 'errand': ['boy'],\n",
              " 'even,': ['if'],\n",
              " 'ever': ['knew!'],\n",
              " 'ever,': ['the'],\n",
              " 'every': ['one', 'one'],\n",
              " 'expect': ['her'],\n",
              " 'explained': ['miss'],\n",
              " 'explained!': ['but'],\n",
              " 'explicit': ['END_OF_SENTENCE'],\n",
              " 'exquisitely': ['set'],\n",
              " 'eye': ['of', 'of'],\n",
              " 'eyes': ['of'],\n",
              " 'face,': ['and'],\n",
              " 'fact!': ['END_OF_SENTENCE'],\n",
              " 'facts': ['are'],\n",
              " 'facts!': ['here'],\n",
              " 'fair': ['client', 'and'],\n",
              " 'famous': ['stone'],\n",
              " 'fashionable': ['hat,', 'doctor,', 'dentist', 'milliner!', 'detective'],\n",
              " 'feebly': ['END_OF_SENTENCE'],\n",
              " 'feet': ['END_OF_SENTENCE'],\n",
              " 'feet,': ['and'],\n",
              " 'felt': ['that'],\n",
              " 'few': ['days', 'years'],\n",
              " 'fifty': ['thousand'],\n",
              " 'film': ['star', 'star', 'actor', 'a'],\n",
              " 'finished': ['miss'],\n",
              " 'fire,': ['exquisitely'],\n",
              " 'first': ['published', 'visit', 'letter'],\n",
              " 'flash': ['of'],\n",
              " 'flat': ['END_OF_SENTENCE'],\n",
              " 'flaw': ['ah,'],\n",
              " 'flocks,': ['mon'],\n",
              " 'followed': ['by'],\n",
              " 'following': ['facts!'],\n",
              " 'follows': ['END_OF_SENTENCE'],\n",
              " 'foolish!': ['a'],\n",
              " 'foolish,': ['monsieur'],\n",
              " 'for': ['the', 'himself', 'that,', 'the', 'her,', 'breath', 'you'],\n",
              " 'forward': ['a'],\n",
              " 'forward,': ['unclosing'],\n",
              " 'francisco': ['that'],\n",
              " 'friday': ['next', 'next', 'we’re'],\n",
              " 'friend': ['joined'],\n",
              " 'friend,': ['it'],\n",
              " 'friends': ['but'],\n",
              " 'frightens': ['me'],\n",
              " 'from': ['the', 'the', 'you', 'a'],\n",
              " 'full': ['of', 'moon?'],\n",
              " 'furs': ['she'],\n",
              " 'furs,': ['her'],\n",
              " 'gave': ['vent'],\n",
              " 'gesticulating': ['as'],\n",
              " 'get': ['no', 'rid'],\n",
              " 'girl': ['a', 'hesitated'],\n",
              " 'girl,': ['gesticulating'],\n",
              " 'girlishlooking,': ['with'],\n",
              " 'give': ['it', 'it'],\n",
              " 'given': ['a'],\n",
              " 'go': ['to', 'mad'],\n",
              " 'god': ['must', 'shall'],\n",
              " 'goes': ['unknown'],\n",
              " 'goes!': ['courez!’'],\n",
              " 'going': ['down'],\n",
              " 'gold': ['pencilcase?'],\n",
              " 'gone': ['the'],\n",
              " 'gossip': ['what', 'which'],\n",
              " 'got': ['the', 'a'],\n",
              " 'gown,': ['drawing'],\n",
              " 'grand': ['metropolitan'],\n",
              " 'great': ['britain',\n",
              "  'detective',\n",
              "  'detective,',\n",
              "  'reception',\n",
              "  'diamond',\n",
              "  'diamond'],\n",
              " 'greeting': ['our'],\n",
              " 'gregory': ['b', 'says', 'bought', 'remembers', 'says', 'b'],\n",
              " 'greg’s': ['wedding'],\n",
              " 'gutenberg': ['ebook', 'license', 'ebook', 'volunteer'],\n",
              " 'had': ['only',\n",
              "  'taken',\n",
              "  'been',\n",
              "  'been',\n",
              "  'been',\n",
              "  'joined',\n",
              "  'imagined',\n",
              "  'paid',\n",
              "  'it',\n",
              "  'rather'],\n",
              " 'hand': ['by', 'me', 'into', 'in', 'and'],\n",
              " 'handbag,': ['and'],\n",
              " 'handed': ['to'],\n",
              " 'handing': ['out'],\n",
              " 'hastings,': ['she', 'hand'],\n",
              " 'hat,': ['magnificent', 'or'],\n",
              " 'have': ['to',\n",
              "  'just',\n",
              "  'recognized',\n",
              "  'you',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'your',\n",
              "  'been',\n",
              "  'not',\n",
              "  'it'],\n",
              " 'he': ['does',\n",
              "  'rises',\n",
              "  'gave',\n",
              "  'is',\n",
              "  'drew',\n",
              "  'seemed',\n",
              "  'only',\n",
              "  'murmured',\n",
              "  'took'],\n",
              " 'head': ['END_OF_SENTENCE', 'limited', 'limited,'],\n",
              " 'hein?': ['poirot'],\n",
              " 'her': ['and,',\n",
              "  'to',\n",
              "  'husband,',\n",
              "  'wonderful',\n",
              "  'furs,',\n",
              "  'jewels,',\n",
              "  'handbag,',\n",
              "  'narrowly',\n",
              "  'hand',\n",
              "  'gown,',\n",
              "  'hand',\n",
              "  'with',\n",
              "  'words'],\n",
              " 'her,': ['she', 'and', 'and'],\n",
              " 'her?': ['or'],\n",
              " 'hercule': ['poirot!'],\n",
              " 'here': ['is', 'END_OF_SENTENCE'],\n",
              " 'herself': ['in'],\n",
              " 'hesitated': ['a'],\n",
              " 'him,': ['and'],\n",
              " 'himself': ['and'],\n",
              " 'his': ['comfortable',\n",
              "  'nephew’s',\n",
              "  'shoulder',\n",
              "  'breath',\n",
              "  'own',\n",
              "  'lordship',\n",
              "  'ancestral'],\n",
              " 'hiss': ['END_OF_SENTENCE'],\n",
              " 'histoire': ['may'],\n",
              " 'hoax': ['gregory', 'but'],\n",
              " 'hotel': ['safe'],\n",
              " 'houses': ['as'],\n",
              " 'how': ['many', 'do', 'wonderfully'],\n",
              " 'hunter’s': ['lodge'],\n",
              " 'hurry': ['to'],\n",
              " 'husband,': ['gregory'],\n",
              " 'i': ['the',\n",
              "  'END_OF_SENTENCE',\n",
              "  'was',\n",
              "  'ejaculated',\n",
              "  'laughed',\n",
              "  'thought',\n",
              "  'once!',\n",
              "  'recognize',\n",
              "  'replied',\n",
              "  'shrugged',\n",
              "  'know',\n",
              "  'ever',\n",
              "  'cried,',\n",
              "  'mistake',\n",
              "  'am',\n",
              "  'tell',\n",
              "  'joined',\n",
              "  'felt',\n",
              "  'just',\n",
              "  'dare',\n",
              "  'am',\n",
              "  'had',\n",
              "  'treated',\n",
              "  'got',\n",
              "  'began',\n",
              "  'had',\n",
              "  'see',\n",
              "  'see,',\n",
              "  'pray',\n",
              "  'complied',\n",
              "  'give',\n",
              "  'counsel',\n",
              "  'just',\n",
              "  'cried,'],\n",
              " 'idly': ['on'],\n",
              " 'if': ['you', 'i'],\n",
              " 'ii': ['the'],\n",
              " 'iii': ['the'],\n",
              " 'imagined': ['END_OF_SENTENCE'],\n",
              " 'impossible': ['END_OF_SENTENCE'],\n",
              " 'in': ['the',\n",
              "  'the',\n",
              "  'great',\n",
              "  'a',\n",
              "  'the',\n",
              "  'a',\n",
              "  'it',\n",
              "  'flocks,',\n",
              "  'england',\n",
              "  'company',\n",
              "  'the',\n",
              "  'greeting',\n",
              "  'the',\n",
              "  'precisely',\n",
              "  'san',\n",
              "  'a',\n",
              "  'three',\n",
              "  'my',\n",
              "  'the',\n",
              "  'platinum,',\n",
              "  'his',\n",
              "  'his',\n",
              "  'my',\n",
              "  'the',\n",
              "  'my',\n",
              "  'california',\n",
              "  'a',\n",
              "  'his'],\n",
              " 'in,': ['and'],\n",
              " 'included': ['with'],\n",
              " 'incurable': ['romanticism'],\n",
              " 'information': ['gregory'],\n",
              " 'innocent': ['victim?', 'blue'],\n",
              " 'inside': ['he'],\n",
              " 'insured': ['for'],\n",
              " 'interested': ['why,'],\n",
              " 'interval,': ['the'],\n",
              " 'into': ['the', 'a'],\n",
              " 'investigates': ['END_OF_SENTENCE',\n",
              "  '***',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE'],\n",
              " 'investigates,': ['by'],\n",
              " 'irish': ['colleen?'],\n",
              " 'is': ['for',\n",
              "  'a',\n",
              "  'coming',\n",
              "  'being',\n",
              "  'this',\n",
              "  'the',\n",
              "  'miss',\n",
              "  'being',\n",
              "  'quite',\n",
              "  'explained!',\n",
              "  'it',\n",
              "  'the',\n",
              "  'unique,',\n",
              "  'coming',\n",
              "  'not',\n",
              "  'no',\n",
              "  'there',\n",
              "  'a',\n",
              "  'true',\n",
              "  'too',\n",
              "  'miss',\n",
              "  'the',\n",
              "  'written',\n",
              "  'what',\n",
              "  'the',\n",
              "  'in'],\n",
              " 'is,': ['mon'],\n",
              " 'it': ['away',\n",
              "  'under',\n",
              "  'was',\n",
              "  'that',\n",
              "  'is',\n",
              "  'well',\n",
              "  'is',\n",
              "  'there',\n",
              "  'is',\n",
              "  'ran',\n",
              "  'came',\n",
              "  'is',\n",
              "  'seemed',\n",
              "  'was',\n",
              "  'was',\n",
              "  'to',\n",
              "  'may',\n",
              "  'with',\n",
              "  'keenly,',\n",
              "  'to',\n",
              "  'about',\n",
              "  'along',\n",
              "  'with',\n",
              "  'now?',\n",
              "  'that',\n",
              "  'came',\n",
              "  'was'],\n",
              " 'it!': ['and'],\n",
              " 'it,': ['give'],\n",
              " 'italian': ['nobleman'],\n",
              " 'its': ['owner,', 'value'],\n",
              " 'it’s': ['only', 'just', 'these', 'locked', 'this', 'one'],\n",
              " 'iv': ['the'],\n",
              " 'ix': ['the'],\n",
              " 'i’ll': ['let'],\n",
              " 'i’m': ['afraid', 'very'],\n",
              " 'january': ['28,'],\n",
              " 'jewel': ['robbery', 'in'],\n",
              " 'jewel,': ['the'],\n",
              " 'jewelcase,': ['and'],\n",
              " 'jewels,': ['above'],\n",
              " 'john': ['lane', 'lane'],\n",
              " 'joined': ['by', 'me', 'with', 'him,'],\n",
              " 'joke,': ['explained'],\n",
              " 'just': ['been', 'must', 'worrying', 'scared', 'brought'],\n",
              " 'keenly,': ['then'],\n",
              " 'keeping': ['until'],\n",
              " 'kidnapped': ['prime'],\n",
              " 'knew!': ['i'],\n",
              " 'know': ['it', 'i'],\n",
              " 'knows': ['it!'],\n",
              " 'knows?': ['i'],\n",
              " 'lady': ['yardly', 'yardly', 'friends', 'yardly’s'],\n",
              " 'lady,': ['richly'],\n",
              " 'lane': ['the', 'company,'],\n",
              " 'language': ['english'],\n",
              " 'last': ['night'],\n",
              " 'lately': ['arrived'],\n",
              " 'latter': ['scrutinized'],\n",
              " 'laughed': ['END_OF_SENTENCE'],\n",
              " 'laws': ['of'],\n",
              " 'lay': ['and'],\n",
              " 'leaned': ['forward,'],\n",
              " 'leaning': ['over'],\n",
              " 'leave': ['it'],\n",
              " 'leaves': ['END_OF_SENTENCE'],\n",
              " 'left': ['eye', 'and', 'by', 'in'],\n",
              " 'less': ['is'],\n",
              " 'let': ['us', 'you'],\n",
              " 'letter': ['was', 'i'],\n",
              " 'letters': ['miss', 'END_OF_SENTENCE'],\n",
              " 'license': ['included'],\n",
              " 'like': ['the'],\n",
              " 'limited': ['END_OF_SENTENCE', 'END_OF_SENTENCE'],\n",
              " 'limited,': ['1924'],\n",
              " 'links': ['END_OF_SENTENCE'],\n",
              " 'little': ['belgian', 'almanac', 'bow', 'secret,'],\n",
              " 'located': ['in', 'before'],\n",
              " 'locked': ['up'],\n",
              " 'lodge': ['END_OF_SENTENCE'],\n",
              " 'london': ['END_OF_SENTENCE', 'in'],\n",
              " 'long': ['thin', 'hiss'],\n",
              " 'looking': ['out', 'up'],\n",
              " 'looks': ['so'],\n",
              " 'lord': ['cronshaw', 'and', 'and', 'yardly'],\n",
              " 'lordship': ['had'],\n",
              " 'lost': ['your'],\n",
              " 'mad': ['over'],\n",
              " 'madame': ['you'],\n",
              " 'madame,': ['that', 'you'],\n",
              " 'madame?': ['he'],\n",
              " 'magnificent': ['furs', 'stone'],\n",
              " 'magnificent,': ['you'],\n",
              " 'make': ['that'],\n",
              " 'manor': ['END_OF_SENTENCE'],\n",
              " 'many': ['times'],\n",
              " 'marks': ['for'],\n",
              " 'marriage': ['had'],\n",
              " 'marsdon': ['manor'],\n",
              " 'marvell': ['on',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'was',\n",
              "  'was',\n",
              "  'unclasped',\n",
              "  'when',\n",
              "  'that’s',\n",
              "  'was',\n",
              "  'nodded'],\n",
              " 'marvell,': ['the', 'her'],\n",
              " 'marvellous!': ['every'],\n",
              " 'mary': ['marvell,', 'marvell', 'marvell', 'marvell', 'marvell,'],\n",
              " 'match': ['its'],\n",
              " 'matter': ['of', 'might'],\n",
              " 'may': ['copy', 'be', 'not!'],\n",
              " 'me': ['at',\n",
              "  'very',\n",
              "  'last',\n",
              "  'to',\n",
              "  'that,',\n",
              "  'END_OF_SENTENCE',\n",
              "  'END_OF_SENTENCE',\n",
              "  'my',\n",
              "  'in'],\n",
              " 'me,': ['n’estce'],\n",
              " 'men': ['and'],\n",
              " 'mere': ['matter'],\n",
              " 'metropolitan': ['END_OF_SENTENCE'],\n",
              " 'middleaged': ['woman'],\n",
              " 'might': ['be'],\n",
              " 'milliner!': ['but'],\n",
              " 'million': ['dollar'],\n",
              " 'mind': ['as', 'some'],\n",
              " 'minister': ['END_OF_SENTENCE'],\n",
              " 'minute': ['he'],\n",
              " 'miss': ['mary',\n",
              "  'mary',\n",
              "  'marvell',\n",
              "  'marvell',\n",
              "  'marvell',\n",
              "  'marvell',\n",
              "  'marvell',\n",
              "  'marvell',\n",
              "  'marvell'],\n",
              " 'missing': ['will'],\n",
              " 'mistake': ['not,'],\n",
              " 'mode,': ['the'],\n",
              " 'moment,': ['then'],\n",
              " 'mon': ['ami?', 'ami,', 'cher?', 'ami,', 'ami!', 'ami!'],\n",
              " 'monsieur': ['poirot,', 'poirot', 'poirot', 'poirot,'],\n",
              " 'moon,': ['the'],\n",
              " 'moon?': ['ah,'],\n",
              " 'more': ['explicit', 'serious'],\n",
              " 'more,': ['some'],\n",
              " 'mortal': ['hurry'],\n",
              " 'most': ['other', 'foolish!', 'popular'],\n",
              " 'movie': ['star'],\n",
              " 'mr': ['davenheim'],\n",
              " 'much,': ['true'],\n",
              " 'murder': ['on'],\n",
              " 'murmured': ['you'],\n",
              " 'must': ['go', 'have', 'return'],\n",
              " 'my': ['breath',\n",
              "  'friend',\n",
              "  'dear',\n",
              "  'shoulders,',\n",
              "  'friend,',\n",
              "  'mind',\n",
              "  'little',\n",
              "  'advice',\n",
              "  'keeping',\n",
              "  'jewelcase,',\n",
              "  'mind'],\n",
              " 'mysterious': ['affair'],\n",
              " 'mystery': ['of', 'of'],\n",
              " 'name': ['and', 'with'],\n",
              " 'narrowly': ['END_OF_SENTENCE'],\n",
              " 'nephew’s': ['death,'],\n",
              " 'next': ['that', 'then'],\n",
              " 'nicknamed,': ['to'],\n",
              " 'night': ['how'],\n",
              " 'no': ['cost', 'restrictions', 'marks', 'fashionable', 'fashionable', 'they'],\n",
              " 'no,': ['no,', 'i’m'],\n",
              " 'nobleman': ['END_OF_SENTENCE'],\n",
              " 'nodded': ['thoughtfully', 'END_OF_SENTENCE'],\n",
              " 'none': ['other'],\n",
              " 'nonessentials!': ['remember'],\n",
              " 'not': ['located', 'END_OF_SENTENCE', 'aristocratic,', 'obeyed', 'come'],\n",
              " 'not!': ['therefore'],\n",
              " 'not,': ['miss'],\n",
              " 'now': ['the'],\n",
              " 'now?': ['a'],\n",
              " 'n’estce': ['pas?'],\n",
              " 'obeyed': ['now'],\n",
              " 'of': ['poirot',\n",
              "  'anyone',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'this',\n",
              "  'the',\n",
              "  'the',\n",
              "  'hunter’s',\n",
              "  'the',\n",
              "  'mr',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'poirot’s',\n",
              "  'his',\n",
              "  'admirers',\n",
              "  'the',\n",
              "  'recognition',\n",
              "  'london',\n",
              "  'curls,',\n",
              "  'the',\n",
              "  'yourself',\n",
              "  'anyone',\n",
              "  'the',\n",
              "  'the',\n",
              "  'fifty',\n",
              "  'a',\n",
              "  'his',\n",
              "  'a',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'its',\n",
              "  'an',\n",
              "  'you,',\n",
              "  'the',\n",
              "  'her',\n",
              "  'white',\n",
              "  'remembrance',\n",
              "  'some',\n",
              "  'a',\n",
              "  'course',\n",
              "  'our',\n",
              "  'the',\n",
              "  'england'],\n",
              " 'on': ['the', 'the', 'the', 'the', 'friday', 'with'],\n",
              " 'once': ['END_OF_SENTENCE'],\n",
              " 'once!': ['yet'],\n",
              " 'one': ['is', 'knows', 'says', 'goes!', 'of', 'was', 'jewel,', 'came', 'of'],\n",
              " 'online': ['at'],\n",
              " 'only': ['lately', 'a', 'asked'],\n",
              " 'opinion': ['of', 'even,'],\n",
              " 'or': ['reuse', 'online', 'are', 'with'],\n",
              " 'other': ['parts', 'than'],\n",
              " 'others': ['share'],\n",
              " 'oui,': ['my'],\n",
              " 'our': ['feet', 'fair', 'arranging'],\n",
              " 'out': ['idly', 'three', 'the', 'any', 'a', 'there'],\n",
              " 'out?': ['END_OF_SENTENCE'],\n",
              " 'over': ['mary', 'his', 'the'],\n",
              " 'own': ['hand'],\n",
              " 'owner,': ['the'],\n",
              " 'pace': ['out'],\n",
              " 'paid': ['a'],\n",
              " 'palm,': ['a'],\n",
              " 'papa': ['poirot?'],\n",
              " 'paper': ['the'],\n",
              " 'parts': ['of'],\n",
              " 'pas?': ['you'],\n",
              " 'passant,': ['my'],\n",
              " 'passed': ['rapidly', 'over'],\n",
              " 'paused': ['for'],\n",
              " 'pencilcase?': ['you'],\n",
              " 'perhaps': ['END_OF_SENTENCE'],\n",
              " 'permit,': ['madame?'],\n",
              " 'pile': ['END_OF_SENTENCE'],\n",
              " 'place': ['about', 'the'],\n",
              " 'places': ['of'],\n",
              " 'placidly,': ['from'],\n",
              " 'platinum,': ['lay'],\n",
              " 'play': ['down'],\n",
              " 'played?': ['is'],\n",
              " 'please': ['END_OF_SENTENCE'],\n",
              " 'plotting': ['to'],\n",
              " 'points': ['after'],\n",
              " 'poirot': ['investigates,',\n",
              "  'investigates',\n",
              "  'investigates',\n",
              "  'investigates',\n",
              "  'investigates',\n",
              "  'investigates',\n",
              "  'investigates',\n",
              "  'placidly,',\n",
              "  'it',\n",
              "  'is',\n",
              "  'was',\n",
              "  'in',\n",
              "  'drew',\n",
              "  'beamed',\n",
              "  'END_OF_SENTENCE',\n",
              "  'nodded',\n",
              "  'was',\n",
              "  'drew',\n",
              "  'as',\n",
              "  'on'],\n",
              " 'poirot!': ['i'],\n",
              " 'poirot,': ['from', 'calming', 'but', 'turning', 'miss'],\n",
              " 'poirot?': ['END_OF_SENTENCE'],\n",
              " 'poirot’s': ['rooms'],\n",
              " 'popular': ['actresses'],\n",
              " 'post,': ['these'],\n",
              " 'pounds': ['END_OF_SENTENCE'],\n",
              " 'pray': ['of'],\n",
              " 'precisely': ['the'],\n",
              " 'prepared': ['to'],\n",
              " 'preparing': ['to'],\n",
              " 'present': ['to'],\n",
              " 'prime': ['minister'],\n",
              " 'printed': ['let', 'like'],\n",
              " 'probably': ['think'],\n",
              " 'problems': ['of'],\n",
              " 'proceed,': ['madame'],\n",
              " 'produced': ['by'],\n",
              " 'project': ['gutenberg', 'gutenberg', 'gutenberg', 'gutenberg'],\n",
              " 'promenade': ['herself'],\n",
              " 'published': ['in'],\n",
              " 'queer,': ['i'],\n",
              " 'quite': ['aware'],\n",
              " 'ran': ['as'],\n",
              " 'rang': ['below'],\n",
              " 'rapidly': ['through'],\n",
              " 'rather': ['feebly', 'gone'],\n",
              " 'really': ['have'],\n",
              " 'really,': ['monsieur'],\n",
              " 'reception': ['every'],\n",
              " 'recognition': ['END_OF_SENTENCE'],\n",
              " 'recognize': ['her,'],\n",
              " 'recognized': ['her'],\n",
              " 'referred': ['to'],\n",
              " 'release': ['date'],\n",
              " 'remember': ['the'],\n",
              " 'remembers': ['that'],\n",
              " 'remembrance': ['in'],\n",
              " 'replied': ['rather', 'constrainedly'],\n",
              " 'reported': ['to'],\n",
              " 'restored': ['it'],\n",
              " 'restrictions': ['whatsoever'],\n",
              " 'return': ['whence', 'so'],\n",
              " 'reuse': ['it'],\n",
              " 'richly': ['dressed'],\n",
              " 'rid': ['of'],\n",
              " 'right': ['after', 'eye'],\n",
              " 'rises': ['to'],\n",
              " 'robbery': ['END_OF_SENTENCE', 'at'],\n",
              " 'rolf': ['END_OF_SENTENCE'],\n",
              " 'rolf,': ['also'],\n",
              " 'romanticism': ['that', 'and'],\n",
              " 'rooms': ['looking'],\n",
              " 'rose': ['to'],\n",
              " 'rule': ['it’s'],\n",
              " 'rumour': ['had'],\n",
              " 'sacré!': ['cried'],\n",
              " 'safe': ['deposit'],\n",
              " 'said': ['poirot,', 'poirot,'],\n",
              " 'saintclair': ['END_OF_SENTENCE'],\n",
              " 'same': ['author', 'terms,'],\n",
              " 'san': ['francisco'],\n",
              " 'say': ['it’s'],\n",
              " 'say?': ['END_OF_SENTENCE'],\n",
              " 'says': ['to', 'so', 'he'],\n",
              " 'scared': ['to'],\n",
              " 'scoundrels,': ['and'],\n",
              " 'screen': ['she'],\n",
              " 'screen,': ['mon'],\n",
              " 'scrutinized': ['them', 'it'],\n",
              " 'second': ['letter'],\n",
              " 'second,': ['i'],\n",
              " 'secret': ['adversary'],\n",
              " 'secret,': ['monsieur'],\n",
              " 'see': ['for', 'the', 'they', 'END_OF_SENTENCE'],\n",
              " 'see,': ['madame,', 'it’s'],\n",
              " 'seek': ['my'],\n",
              " 'seemed': ['to', 'just'],\n",
              " 'seems': ['of'],\n",
              " 'seen': ['mary'],\n",
              " 'sentence,': ['carefully'],\n",
              " 'serious': ['than'],\n",
              " 'set': ['encoding', 'in'],\n",
              " 'shadowed': ['by'],\n",
              " 'shadowers': ['detectives'],\n",
              " 'shall': ['return'],\n",
              " 'share': ['that'],\n",
              " 'she': ['is',\n",
              "  'goes',\n",
              "  'is',\n",
              "  'is',\n",
              "  'is',\n",
              "  'looks',\n",
              "  'is',\n",
              "  'had',\n",
              "  'commenced',\n",
              "  'paused',\n",
              "  'handed',\n",
              "  'replied',\n",
              "  'leaned'],\n",
              " 'short': ['interval,'],\n",
              " 'shoulder': ['the'],\n",
              " 'shoulders,': ['slightly'],\n",
              " 'show': ['places'],\n",
              " 'shrugged': ['my'],\n",
              " 'silly': ['hoax'],\n",
              " 'simplest': ['course'],\n",
              " 'simply': ['this'],\n",
              " 'single': ['sentence,'],\n",
              " 'slender,': ['very'],\n",
              " 'slight': ['cloud'],\n",
              " 'slightly': ['annoyed'],\n",
              " 'slipped': ['her'],\n",
              " 'slowly,': ['looking'],\n",
              " 'small': ['and'],\n",
              " 'so': ['what', 'all', 'different,', 'but', 'it', 'at'],\n",
              " 'solemnly': ['END_OF_SENTENCE'],\n",
              " 'some': ['story', 'gossip', 'lady', 'gossip', 'chance'],\n",
              " 'something': ['more,'],\n",
              " 'spend': ['a'],\n",
              " 'standing': ['at'],\n",
              " 'star': ['END_OF_SENTENCE', 'END_OF_SENTENCE', 'she', 'was', 'much,', 'in'],\n",
              " 'star,’': ['finished'],\n",
              " 'start': ['of'],\n",
              " 'states': ['and', 'and'],\n",
              " 'states,': [\"you'll\", 'rumour'],\n",
              " 'staying': ['at'],\n",
              " 'steps': ['we'],\n",
              " 'still': ['less', 'in'],\n",
              " 'stone': ['which', 'three', 'of', 'without'],\n",
              " 'stone,': ['but'],\n",
              " 'story': ['attached', 'seems'],\n",
              " 'street': ['below'],\n",
              " 'street,': ['it'],\n",
              " 'streets': ['of'],\n",
              " 'styles': ['END_OF_SENTENCE'],\n",
              " 'suddenly': ['beneath'],\n",
              " 'sum': ['of'],\n",
              " 'surely': ['there'],\n",
              " 'take': ['what'],\n",
              " 'taken': ['place', 'from'],\n",
              " 'talking': ['at'],\n",
              " 'tell': ['you?'],\n",
              " 'telling': ['me'],\n",
              " 'tenth': ['of'],\n",
              " 'terms': ['of'],\n",
              " 'terms,': ['but'],\n",
              " 'than': ['i', 'gregory'],\n",
              " 'that': ['is',\n",
              "  'you',\n",
              "  'opinion',\n",
              "  'out?',\n",
              "  'is',\n",
              "  'i',\n",
              "  'is',\n",
              "  'gregory',\n",
              "  'you',\n",
              "  'there',\n",
              "  'is',\n",
              "  'his',\n",
              "  'of'],\n",
              " 'that,': ['poirot', 'after'],\n",
              " 'that’s': ['queer,', 'so', 'impossible'],\n",
              " 'the': ['use',\n",
              "  'united',\n",
              "  'world',\n",
              "  'terms',\n",
              "  'project',\n",
              "  'united',\n",
              "  'laws',\n",
              "  'country',\n",
              "  'same',\n",
              "  'mysterious',\n",
              "  'secret',\n",
              "  'murder',\n",
              "  'links',\n",
              "  'bodley',\n",
              "  'bodley',\n",
              "  'bodley',\n",
              "  'adventure',\n",
              "  'western',\n",
              "  'tragedy',\n",
              "  'adventure',\n",
              "  'cheap',\n",
              "  'mystery',\n",
              "  'million',\n",
              "  'adventure',\n",
              "  'egyptian',\n",
              "  'grand',\n",
              "  'kidnapped',\n",
              "  'disappearance',\n",
              "  'adventure',\n",
              "  'italian',\n",
              "  'case',\n",
              "  'missing',\n",
              "  'adventure',\n",
              "  'western',\n",
              "  'window',\n",
              "  'street',\n",
              "  'depths',\n",
              "  'following',\n",
              "  'houses',\n",
              "  'girl,',\n",
              "  'girl',\n",
              "  'shadowers',\n",
              "  'scoundrels,',\n",
              "  'great',\n",
              "  'great',\n",
              "  'simplest',\n",
              "  'window',\n",
              "  'film',\n",
              "  'fact!',\n",
              "  'screen,',\n",
              "  'streets',\n",
              "  'nonessentials!',\n",
              "  'case',\n",
              "  'dancer,',\n",
              "  'best',\n",
              "  'mode,',\n",
              "  'dernier',\n",
              "  'little',\n",
              "  'most',\n",
              "  'american',\n",
              "  'most',\n",
              "  'screen',\n",
              "  'states',\n",
              "  'great',\n",
              "  'western',\n",
              "  'enormous',\n",
              "  'wide',\n",
              "  'mystery',\n",
              "  'dark',\n",
              "  'latter',\n",
              "  'name',\n",
              "  'inside',\n",
              "  'enclosure',\n",
              "  'writing',\n",
              "  'envelope',\n",
              "  'great',\n",
              "  'left',\n",
              "  'god',\n",
              "  'second',\n",
              "  'same',\n",
              "  'third',\n",
              "  'diamond',\n",
              "  'full',\n",
              "  'moon,',\n",
              "  'two',\n",
              "  'left',\n",
              "  'god',\n",
              "  'first',\n",
              "  'second,',\n",
              "  'third',\n",
              "  'matter',\n",
              "  'stone',\n",
              "  'diamond',\n",
              "  'western',\n",
              "  'time,',\n",
              "  'stone,',\n",
              "  'chink',\n",
              "  'thing',\n",
              "  'story',\n",
              "  'leaves',\n",
              "  'date',\n",
              "  'full',\n",
              "  'diamond',\n",
              "  'actress’s',\n",
              "  'girl',\n",
              "  'bosom',\n",
              "  'palm,',\n",
              "  'jewel',\n",
              "  'hotel',\n",
              "  'magnificent,',\n",
              "  'states,',\n",
              "  'pace',\n",
              "  'assistance',\n",
              "  'show'],\n",
              " 'their': ['marriage', 'first'],\n",
              " 'them': ['closely'],\n",
              " 'then': ['we', 'slipped', 'restored'],\n",
              " 'there': ['is', 'a', 'is', 'was', 'with', 'was', 'in'],\n",
              " 'therefore': ['i'],\n",
              " 'there’s': ['some'],\n",
              " 'these': ['details', 'letters', 'letters'],\n",
              " 'they': ['have', 'the', 'plotting', 'arrive!', 'had', 'did', 'were'],\n",
              " 'thin': ['chain'],\n",
              " 'thing': ['he'],\n",
              " 'think': ['me'],\n",
              " 'third': ['was', 'one'],\n",
              " 'this': ['ebook',\n",
              "  'ebook',\n",
              "  'ebook',\n",
              "  'project',\n",
              "  'being',\n",
              "  'street,',\n",
              "  'was',\n",
              "  'famous',\n",
              "  'belle',\n",
              "  'way,'],\n",
              " 'thought': ['END_OF_SENTENCE'],\n",
              " 'thoughtfully': ['END_OF_SENTENCE'],\n",
              " 'thousand': ['pounds'],\n",
              " 'three': ['men', 'envelopes', 'years', 'days’'],\n",
              " 'through': ['my'],\n",
              " 'time': ['eh'],\n",
              " 'time,': ['gregory'],\n",
              " 'times': ['have', 'perhaps'],\n",
              " 'tinged': ['with'],\n",
              " 'title': ['poirot'],\n",
              " 'to': ['check',\n",
              "  'her,',\n",
              "  'arrest',\n",
              "  'attack',\n",
              "  'see',\n",
              "  'an',\n",
              "  'promenade',\n",
              "  'another',\n",
              "  'the',\n",
              "  'our',\n",
              "  'england',\n",
              "  'go',\n",
              "  'match',\n",
              "  'be',\n",
              "  'death',\n",
              "  'poirot',\n",
              "  'wonder',\n",
              "  'me',\n",
              "  'to',\n",
              "  'be',\n",
              "  'the',\n",
              "  'death,',\n",
              "  'get',\n",
              "  'me',\n",
              "  'you',\n",
              "  'place',\n",
              "  'her',\n",
              "  'see',\n",
              "  'yardly',\n",
              "  'spend',\n",
              "  'the',\n",
              "  'me',\n",
              "  'film'],\n",
              " 'today': ['for'],\n",
              " 'tomb': ['END_OF_SENTENCE'],\n",
              " 'tonnerres!': ['and'],\n",
              " 'too': ['marvellous!'],\n",
              " 'took': ['the'],\n",
              " 'tragedy': ['at'],\n",
              " 'treated': ['as'],\n",
              " 'true': ['i', 'and'],\n",
              " 'turning': ['the'],\n",
              " 'two': ['diamonds'],\n",
              " 'unbelievable': ['romanticism'],\n",
              " 'unclasped': ['her'],\n",
              " 'unclosing': ['her'],\n",
              " 'under': ['the'],\n",
              " 'undoubtedly': ['one'],\n",
              " 'unique,': ['one'],\n",
              " 'united': ['states', 'states,'],\n",
              " 'unknown': ['to'],\n",
              " 'until': ['after'],\n",
              " 'untrue,': ['had'],\n",
              " 'up': ['at', 'the', 'in'],\n",
              " 'us': ['see', 'solemnly'],\n",
              " 'use': ['of'],\n",
              " 'ushered': ['in,'],\n",
              " 'using': ['this'],\n",
              " 'usual,': ['your', 'poirot'],\n",
              " 'utf8': ['END_OF_SENTENCE'],\n",
              " 'v': ['the'],\n",
              " 'vague': ['echo'],\n",
              " 'valerie': ['saintclair'],\n",
              " 'value': ['it'],\n",
              " 'vent': ['to'],\n",
              " 'very': ['simply', 'fair', 'foolish,', 'careful'],\n",
              " 'vi': ['the'],\n",
              " 'victim?': ['what'],\n",
              " 'vii': ['jewel'],\n",
              " 'viii': ['the'],\n",
              " 'visit': ['to', 'to'],\n",
              " 'volunteer': ['END_OF_SENTENCE'],\n",
              " 'voyons!': ['said'],\n",
              " 'vérité!': ['and'],\n",
              " 'warned': ['you'],\n",
              " 'was': ['standing',\n",
              "  'a',\n",
              "  'right',\n",
              "  'ushered',\n",
              "  'undoubtedly',\n",
              "  'their',\n",
              "  'prepared',\n",
              "  'reported',\n",
              "  'small',\n",
              "  'telling',\n",
              "  'leaning',\n",
              "  'couched',\n",
              "  'more',\n",
              "  'from',\n",
              "  'some',\n",
              "  'greg’s',\n",
              "  'watching',\n",
              "  'it',\n",
              "  'something',\n",
              "  'none',\n",
              "  'continuing'],\n",
              " 'wasn’t': ['handing'],\n",
              " 'watching': ['her'],\n",
              " 'way,': ['monsieur'],\n",
              " 'we': ['rose', 'can', 'please'],\n",
              " 'wedding': ['present'],\n",
              " 'well': ['END_OF_SENTENCE'],\n",
              " 'well,': ['you'],\n",
              " 'were': ['left'],\n",
              " 'western': ['star', 'star', 'star', 'star,’'],\n",
              " 'we’re': ['staying', 'going'],\n",
              " 'we’ve': ['got'],\n",
              " 'what': ['is,', 'drama', 'does', 'will', 'did', 'frightens', 'steps', 'was'],\n",
              " 'what?': ['END_OF_SENTENCE'],\n",
              " 'whatsoever': ['you'],\n",
              " 'when': ['one', 'i', 'is'],\n",
              " 'whence': ['it'],\n",
              " 'where': ['you'],\n",
              " 'which': ['had', 'was', 'she', 'is', 'are', 'coupled'],\n",
              " 'white': ['fire,'],\n",
              " 'who': ['points', 'have', 'knows?'],\n",
              " 'why!': ['it'],\n",
              " 'why,': ['it’s'],\n",
              " 'why?': ['END_OF_SENTENCE'],\n",
              " 'wide': ['innocent'],\n",
              " 'will': ['END_OF_SENTENCE', 'you?', 'probably', 'be', 'leave', 'be'],\n",
              " 'window': ['of', 'END_OF_SENTENCE'],\n",
              " 'winked': ['at'],\n",
              " 'with': ['almost',\n",
              "  'this',\n",
              "  'your',\n",
              "  'bare',\n",
              "  'you',\n",
              "  'problems',\n",
              "  'her',\n",
              "  'poirot',\n",
              "  'the',\n",
              "  'you',\n",
              "  'a',\n",
              "  'a',\n",
              "  'you,',\n",
              "  'me,',\n",
              "  'lord',\n",
              "  'the',\n",
              "  'that',\n",
              "  'lord'],\n",
              " 'without': ['doubt', 'a'],\n",
              " 'woman': ['they'],\n",
              " 'wonder': ['the'],\n",
              " 'wonderful': ['clothes,'],\n",
              " 'wonderfully': ['you'],\n",
              " 'words': ['awoke'],\n",
              " 'world': ['at'],\n",
              " 'worrying': ['me'],\n",
              " 'writing': ['consisted'],\n",
              " 'written': ['about', 'END_OF_SENTENCE'],\n",
              " 'www.gutenberg.org': ['if'],\n",
              " 'x': ['the'],\n",
              " 'xi': ['the'],\n",
              " 'yardly': ['chase', 'END_OF_SENTENCE', 'had', 'there’s', 'chase?'],\n",
              " 'yardly’s': ['name'],\n",
              " 'year': ['ago'],\n",
              " 'years': ['ago', 'ago'],\n",
              " 'yesterday,': ['and'],\n",
              " 'yet': ['i', 'who'],\n",
              " 'you': ['may',\n",
              "  'are',\n",
              "  'are',\n",
              "  'get',\n",
              "  'seen',\n",
              "  'do',\n",
              "  'expect',\n",
              "  'it',\n",
              "  'really',\n",
              "  'make',\n",
              "  'have',\n",
              "  'must',\n",
              "  'will',\n",
              "  'cleared',\n",
              "  'comprehend,',\n",
              "  'have',\n",
              "  'have',\n",
              "  'at',\n",
              "  'believe',\n",
              "  'seek',\n",
              "  'this',\n",
              "  'to',\n",
              "  'have',\n",
              "  'hein?',\n",
              "  'permit,',\n",
              "  'carry',\n",
              "  'know',\n",
              "  'to',\n",
              "  'will',\n",
              "  'will',\n",
              "  'see,',\n",
              "  'into'],\n",
              " \"you'll\": ['have'],\n",
              " 'you,': ['hastings,', 'comme'],\n",
              " 'you?': ['when', 'that'],\n",
              " 'young': ['lady,'],\n",
              " 'your': ['facts', 'incurable', 'gold', 'advice'],\n",
              " 'yourself': ['of'],\n",
              " 'yourself,': ['mon'],\n",
              " '©': ['1924'],\n",
              " 'ça!': ['END_OF_SENTENCE'],\n",
              " 'épatant!': ['he'],\n",
              " '\\ufeffthe': ['project']}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lessons learned: Running the whole 4k (accidentally repeatedly appended) gave the error \n",
        "\n",
        "Ha ha ha! -- I had 2 appends... I fixed it (doubling grains of rice on a chess board territory. Oop!) \n",
        "\n",
        "\"IOPub data rate exceeded.\n",
        "The notebook server will temporarily stop sending output\n",
        "to the client in order to avoid crashing it.\n",
        "To change this limit, set the config variable\n",
        "`--NotebookApp.iopub_data_rate_limit`.\"\n",
        "\n",
        "Current values:\n",
        "* NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
        "* NotebookApp.rate_limit_window=3.0 (secs)\n"
      ],
      "metadata": {
        "id": "1cXn9EJM5FoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate new sentences\n",
        "\n",
        "Finally, the big pay-off! In this step, you'll implement the function `generate_sentence`. The first word in a sentence is always one of the words from the \"START_OF_SENTENCE\" key. Then, the next word must come from the words for that start word's key in the chain. Keep picking words until the chosen word is \"END_OF_SENTENCE\".\n",
        "\n",
        "At the beginning we said that Markov chains are probabilistic: some words are more likely to come after words than other words. How can you randomly choose words so that we're more likely to choose the most common words after? Well, since the values in the chain store a word each time it's seen, that means that randomly picking from that list of words _will_ end up picking those repeated words more often than others. So you can just use that handy `random.choice(list)` function on the list, and it'll just work.\n"
      ],
      "metadata": {
        "id": "sIsF6f89jXgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_sentence(chain):\n",
        "  \"\"\"\n",
        "  >>> test_chain = {'START_OF_SENTENCE': ['i'], 'i': ['am'], 'am': ['happy'], 'happy': ['END_OF_SENTENCE']}\n",
        "  >>> generate_sentence(test_chain)\n",
        "  'i am happy'\n",
        "  \"\"\"\n",
        "  # Initialize a list to hold the words for the new sentence\n",
        "  words = []\n",
        "\n",
        "  # Select the first word randomly from all possible start words\n",
        "  random_word = random.choice(chain[\"START_OF_SENTENCE\"])\n",
        "\n",
        "  # Append the first word to the new sentence\n",
        "  words.append(random_word)\n",
        "\n",
        "  # Keep looping, selecting the next word to come after\n",
        "  # and adding it to the new sentence\n",
        "  # until the word reached is \"END_OF_SENTENCE\"\n",
        "  #\n",
        "  while True:\n",
        "      new_word = random.choice(chain[random_word])\n",
        "      if new_word == \"END_OF_SENTENCE\":\n",
        "        break\n",
        "      random_word = new_word\n",
        "      words.append(random_word)\n",
        "\n",
        "  # Return the sentence as a string (instead of a list of words)\n",
        "  return \" \".join(words)"
      ],
      "metadata": {
        "id": "HYqrZs2-NBLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests when you think add_sentence is working\n",
        "import doctest\n",
        "doctest.run_docstring_examples(generate_sentence, globals(), verbose=True, name=\"generate_sentence\")"
      ],
      "metadata": {
        "id": "rzkpa6LBrJWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae95e63a-d835-4cf2-bc7e-e59d1a7795a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding tests in generate_sentence\n",
            "Trying:\n",
            "    test_chain = {'START_OF_SENTENCE': ['i'], 'i': ['am'], 'am': ['happy'], 'happy': ['END_OF_SENTENCE']}\n",
            "Expecting nothing\n",
            "ok\n",
            "Trying:\n",
            "    generate_sentence(test_chain)\n",
            "Expecting:\n",
            "    'i am happy'\n",
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏︎ For you to do\n",
        "\n",
        "Run the code below to generate a sentence with your chain. Each time you run it, you should see a new sentence. "
      ],
      "metadata": {
        "id": "ibAbP_APrKWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sentence(chain) # \"so all these letters\" ;-D "
      ],
      "metadata": {
        "id": "LLDoRq8QNz3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05d59bb7-5988-444c-e497-c137fefc0907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'so all these letters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sentence(chain)\n",
        "# I can see this getting mad libs quite soon \n",
        "# \n",
        "# \"i mistake not, miss marvell unclasped her gown, \n",
        "#  drawing out any information gregory says to be a vague echo of an irish colleen? \n",
        "# always with almost no fashionable dentist still in the million dollar bond robbery at marsdon manor\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S79C5gVm92xn",
        "outputId": "c3ad1746-cb70-4a64-dd9e-a2c51f2670ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i mistake not, miss marvell unclasped her gown, drawing out any information gregory says to be a vague echo of an irish colleen? always with almost no fashionable dentist still in the million dollar bond robbery at marsdon manor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You're done!\n",
        "\n",
        "🎉 Woohoo! 🥳 Project 3! 👏🏽 Complete! 🎊 \n",
        "\n",
        "Remember to share your project and your favorite generated sentences with your classmates. I can't wait to see them!"
      ],
      "metadata": {
        "id": "eMqMnefQvfWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extensions\n",
        "\n",
        "If you enjoyed this project and want to take it further, there are many ways to affect the behavior of a Markov chain. Some ideas:\n",
        "\n",
        "* **New data source**: Try a different data source than the one you originally tested with, or go out and try to find a brand new data source. You might find text files online, you could fetch data from an API (like [The Movie Database API](https://developers.themoviedb.org/3)), or you could scrape data from a website using the [BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) (check the website terms first).\n",
        "* **Better punctuation support**: What happens right now if a sentence contains commas, hyphens, or other sorts of punctuation? How does that affect the result of your chain? Think about what sort of string processing you might do to handle punctuation better, and whether you'd want to strip some punctuation entirely or store some punctuation symbols as \"words\" in the chain.\n",
        "* **Multiple sentence support**: Very related to above, what if a line contains multiple sentences? How will the chain currently treat that situation? See if you can come up with a more robust handling.\n",
        "* **Bigrams**: The chain is currently based on \"unigrams\": single words and their likelihood of being followed by another word. One way to make the chain produce more natural language is to instead use \"bigrams\" - pairs of words. The chain would store bigrams in the keys instead of single words. Then, when generating sentences, it would need to look up the next word based on the most recent _two_ words in the sentence, not just the most recent word. \n",
        "\n",
        "Enjoy, and let us know if you try out any of the extensions!"
      ],
      "metadata": {
        "id": "OZ3lfr3pQ2Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thoughts \n",
        "\n",
        "This book would be so **awesome** to markov chain just because of the word \"Woddly\" and add random emoji's <3 \n",
        "After I did this work I went looking for the book in the Gutenberg Project and did not find it :( \n",
        "\n",
        "https://www.amazon.com/Great-Quillow-James-Thurber/dp/0152325441\n",
        "\n"
      ],
      "metadata": {
        "id": "HXgheitI_p7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Assessment \n",
        "\n",
        "\n",
        "* Are the tests passing for all the functions (wordify_sentence, add_sentence, generate_sentence)? Yes \n",
        "\n",
        "* What was the trickiest part of this project?\n",
        "Realizing my initial work on cleaned_sentences where I combined code I was working in two notebook paragraphs - accidentally kept adding to the list and made upmteen-cates then when trying to search for \"the\" the notebook bombed (ha ha ha) so I then had to go back to first principles.\n",
        "\n",
        "* Is there anywhere you are still stuck or confused? I'd like to add random punctuation, but I am torn if I should only catalog that list from the source or just tell my code to pull from the dictionary that I created. \n",
        "\n",
        "* Or any particular part of the code you’d like focused feedback on? Wondering how folks kept track of their punctuation when breaking out sentences in initial load. I did like that my sentences were long when the original sentence was long and short when the sentence was short. \n",
        "\n",
        "* What’s your favorite output from your chain so far?\n",
        "\"poirot is a fashionable dentist still less is coming along slowly, looking up at the screen, mon ami? asked about a bevy of a stone without doubt she is a few years ago in a joke, explained miss mary marvell unclasped her narrowly\"\n",
        "\n",
        "* If you could improve the output from this chain in one way, what would it be?Wondering if I can catalog random exclamations as the mystery book by Agatha Christie has them peppered in the book, yet they all got lumped in to the main list. And adding in random punctuation. \n"
      ],
      "metadata": {
        "id": "fJI0zSM8_6EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Peer Review\n",
        "\n",
        "When your partners post their projects, please peer review them by answering the following questions via a threaded reply on their Slack post (due EOD Monday):\n",
        "* Generate a few sentences and share your favorite output.\n",
        "* How similar was their approach to your own approach? Any notable differences in your functions (like wordify_sentence)?\n",
        "* What’s one way they might improve their project? For example, you might have * ideas for how their code could be cleaner. If they indicated in their self-assessment that they were stuck and/or want focused feedback, please provide ideas if you can.\n",
        "* Any additional thoughts? Feel free to add words of encouragement as well.\n"
      ],
      "metadata": {
        "id": "rdQ1FJ4hASdc"
      }
    }
  ]
}